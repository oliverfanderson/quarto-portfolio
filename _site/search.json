[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Oliver F. Anderson, MS",
    "section": "",
    "text": "Oliver F. Anderson, MS ‚Äì Computational Biologist, Data Scientist, and Research Consultant based in Portland, Oregon. I design data-driven solutions in bioinformatics, machine learning, and AI automation for research and biotech."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "GRPhIN: Graphlet Characterization of Regulatory and Physical Interaction Networks\n\n\n\nacademic\n\nalgorithms\n\nbiology\n\nnetworks\n\nstatistical testing\n\ncomputational biology\n\nsoftware engineering\n\nPython\n\n\n\nGRPhIN is an algorithm for enumerating 2- and 3-node graphlets and their orbits in mixed regulatory and physical interaction networks. Published in Bioinformatics Advances.\n\n\n\n\n\nApr 3, 2025\n\n\nOliver F. Anderson\n\n\n\n\n\n\n\n\n\n\n\n\nProteinWeaver: Visualizing Biological Networks in their Functional Context\n\n\n\nacademic\n\nbiology\n\ncomputational biology\n\nnetworks\n\ndata visualization\n\ndata science\n\nsoftware engineering\n\nDocker\n\nR\n\nCypher\n\nPython\n\nJavaScript\n\n\n\nProteinWeaver is a web-based tool that maps molecular interaction networks to biological functions and processes using Gene Ontology terms. Published in PLOS ONE.\n\n\n\n\n\nJul 5, 2024\n\n\nOliver F. Anderson\n\n\n\n\n\n\n\n\n\n\n\n\nBiodegradation of PET Plastic: RNA-seq Analysis and Enzyme Discovery\n\n\n\nacademic\n\ncomputational biology\n\nbiology\n\nbioinformatics\n\ndata science\n\nbash\n\n\n\nUndergraduate thesis project combining bioinformatics and biology to identify enzymes involved in PET plastic biodegradation. RNA-seq pipeline, metabolic pathway analysis, and publication in IJMS.\n\n\n\n\n\nJul 4, 2024\n\n\nOliver F. Anderson\n\n\n\n\n\n\n\n\n\n\n\n\nInteractive Data Visualization in R with plotly and ggiraph\n\n\n\nhealth analysis\n\ndata science\n\ndata wrangling\n\nR\n\ndata visualization\n\nR projects\n\n\n\nBuild interactive graphics in R using plotly and ggiraph. Explore sunshine data across U.S. cities, compare patterns, and highlight anomalies.\n\n\n\n\n\nFeb 16, 2023\n\n\nOliver F. Anderson\n\n\n\n\n\n\n\n\n\n\n\n\nSuper Bowl Champions: Analysis Using the gt R Package\n\n\n\nsports analytics\n\ndata science\n\ndata wrangling\n\nR\n\ndata visualization\n\nR projects\n\n\n\nExplore the Super Bowl champions‚Äô (2023 and before) table with game number, date, scores, teams, locations, and team logos.\n\n\n\n\n\nFeb 13, 2023\n\n\nOliver F. Anderson\n\n\n\n\n\n\n\n\n\n\n\n\nBuilding a Remote Currency Database with Docker and API Scraping\n\n\n\nanalysis\n\ncode\n\ndata wrangling\n\nbash\n\ndocker\n\nSQL\n\nR\n\nweb scraping\n\ndata engineering\n\ndatabases\n\n\n\nA remote SQL currency database built with Docker and daily API scraping, linked with GDP data to study exchange-rate effects.\n\n\n\n\n\nNov 25, 2022\n\n\nOliver F. Anderson\n\n\n\n\n\n\n\n\n\n\n\n\nInteractive Map in R with Shiny and Leaflet\n\n\n\nhealth analytics\n\ndata science\n\ndata wrangling\n\nR\n\ndata visualization\n\nShiny apps\n\nLeaflet\n\n\n\nAn interactive map of CDC health data using Shiny and Leaflet in R. Explore nutrition, exercise, and obesity trends across U.S. states.\n\n\n\n\n\nNov 23, 2022\n\n\nOliver F. Anderson\n\n\n\n\n\n\n\n\n\n\n\n\nOlympic Track & Field Body Composition: Event-Level Patterns\n\n\n\nhealth analytics\n\nsports analytics\n\nR projects\n\ndata science\n\nR\n\ndata visualization\n\ndata wrangling\n\n\n\nHeight‚Äìweight patterns of Olympic track and field medalists by event, using #TidyTuesday data (2021-07-27).\n\n\n\n\n\nFeb 5, 2023\n\n\nOliver F. Anderson\n\n\n\n\n\nNo matching items\nOliver F. Anderson, MS ‚Äì Computational Biologist, Data Scientist, and Research Consultant based in Portland, Oregon. I design data-driven solutions in bioinformatics, machine learning, and AI automation for research and biotech. Back to top"
  },
  {
    "objectID": "posts/super-bowl-winners.html",
    "href": "posts/super-bowl-winners.html",
    "title": "Super Bowl Champions: Analysis Using the gt R Package",
    "section": "",
    "text": "In celebration of the 2023 Super Bowl, I explored the gt R package to analyze the historical data of teams that emerged victorious since the inaugural Super Bowl. Using gt, I created a comprehensive table that presents an overview of Super Bowl champions throughout the years.\nTo begin, I loaded the necessary packages and imported the Super Bowl dataset. I also incorporated team logos into the table for enhanced visual appeal.\nWith the flexibility of the gt package, I curated and formatted the table columns, highlighting essential information such as the Super Bowl number, date, winning and losing teams, points scored, and the event‚Äôs location. This table serves as a valuable resource for gaining insights into the historical context and achievements of each Super Bowl.\n\n\nLook at the code\n# load packages and read in data\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(lubridate)\n\nsuperbowls &lt;- readr::read_csv('./Super_Bowl.csv')\n \n# add logos for each team\nsuperbowls &lt;- superbowls %&gt;% \n  mutate(win_logo_url = \n  case_when(\n          Winner == \"Green Bay Packers\" ~ \"https://upload.wikimedia.org/wikipedia/commons/5/50/Green_Bay_Packers_logo.svg\",\n          Winner == \"New York Jets\" ~ \"https://upload.wikimedia.org/wikipedia/en/6/6b/New_York_Jets_logo.svg\",\n          Winner == \"Kansas City Chiefs\" ~ \"https://upload.wikimedia.org/wikipedia/en/e/e1/Kansas_City_Chiefs_logo.svg\",\n          Winner == \"Baltimore Colts\" ~ \"https://upload.wikimedia.org/wikipedia/en/1/1f/Baltimore_Colts_logo_1961-1978.gif\",\n          Winner == \"Dallas Cowboys\" ~ \"https://upload.wikimedia.org/wikipedia/commons/1/15/Dallas_Cowboys.svg\",\n          Winner == \"Miami Dolphins\" ~ \"https://upload.wikimedia.org/wikipedia/en/3/37/Miami_Dolphins_logo.svg\",\n          Winner == \"Pittsburgh Steelers\" ~ \"https://upload.wikimedia.org/wikipedia/commons/d/de/Pittsburgh_Steelers_logo.svg\",\n          Winner == \"Oakland Raiders\" ~ \"https://upload.wikimedia.org/wikipedia/en/4/48/Las_Vegas_Raiders_logo.svg\",\n          Winner == \"Los Angeles Raiders\" ~ \"https://upload.wikimedia.org/wikipedia/en/4/48/Las_Vegas_Raiders_logo.svg\",\n          Winner == \"San Francisco 49ers\" ~ \"https://upload.wikimedia.org/wikipedia/commons/3/3a/San_Francisco_49ers_logo.svg\",\n          Winner == \"Washington Redskins\" ~ \"https://e7.pngegg.com/pngimages/193/260/png-clipart-redskins-logo-red-skins-logo-sports-nfl-football.png\",\n          Winner == \"Chicago Bears\" ~ \"https://upload.wikimedia.org/wikipedia/commons/5/5c/Chicago_Bears_logo.svg\",\n          Winner == \"New York Giants\" ~ \"https://upload.wikimedia.org/wikipedia/commons/6/60/New_York_Giants_logo.svg\",\n          Winner == \"Denver Broncos\" ~ \"https://upload.wikimedia.org/wikipedia/en/4/44/Denver_Broncos_logo.svg\",\n          Winner == \"St. Louis Rams\" ~ \"https://upload.wikimedia.org/wikipedia/en/8/8b/NFL_Rams_logo.svg\",\n          Winner == \"Baltimore Ravens\" ~ \"https://upload.wikimedia.org/wikipedia/en/1/16/Baltimore_Ravens_logo.svg\",\n          Winner == \"New England Patriots\" ~ \"https://upload.wikimedia.org/wikipedia/en/b/b9/New_England_Patriots_logo.svg\",\n          Winner == \"Tampa Bay Buccaneers\" ~ \"https://upload.wikimedia.org/wikipedia/en/a/a2/Tampa_Bay_Buccaneers_logo.svg\",\n          Winner == \"Indianapolis Colts\" ~ \"https://upload.wikimedia.org/wikipedia/commons/0/00/Indianapolis_Colts_logo.svg\",\n          Winner == \"New Orleans Saints\" ~ \"https://upload.wikimedia.org/wikipedia/commons/5/50/New_Orleans_Saints_logo.svg\",\n          Winner == \"Seattle Seahawks\" ~ \"https://upload.wikimedia.org/wikipedia/en/8/8e/Seattle_Seahawks_logo.svg\",\n          Winner == \"Philadelphia Eagles\" ~ \"https://upload.wikimedia.org/wikipedia/en/8/8e/Philadelphia_Eagles_logo.svg\"\n          )\n       ) %&gt;% \n  mutate(lose_logo_url = \n  case_when(\n          Loser == \"Green Bay Packers\" ~ \"https://upload.wikimedia.org/wikipedia/commons/5/50/Green_Bay_Packers_logo.svg\",\n            Loser == \"Minnesota Vikings\" ~ \"https://upload.wikimedia.org/wikipedia/en/4/48/Minnesota_Vikings_logo.svg\",\n          Loser == \"Kansas City Chiefs\" ~ \"https://upload.wikimedia.org/wikipedia/en/e/e1/Kansas_City_Chiefs_logo.svg\",\n          Loser == \"Baltimore Colts\" ~ \"https://upload.wikimedia.org/wikipedia/en/1/1f/Baltimore_Colts_logo_1961-1978.gif\",\n          Loser == \"Dallas Cowboys\" ~ \"https://upload.wikimedia.org/wikipedia/commons/1/15/Dallas_Cowboys.svg\",\n          Loser == \"Miami Dolphins\" ~ \"https://upload.wikimedia.org/wikipedia/en/3/37/Miami_Dolphins_logo.svg\",\n          Loser == \"Pittsburgh Steelers\" ~ \"https://upload.wikimedia.org/wikipedia/commons/d/de/Pittsburgh_Steelers_logo.svg\",\n          Loser == \"Oakland Raiders\" ~ \"https://upload.wikimedia.org/wikipedia/en/4/48/Las_Vegas_Raiders_logo.svg\",\n          Loser == \"Los Angeles Rams\" ~ \"https://upload.wikimedia.org/wikipedia/en/8/8a/Los_Angeles_Rams_logo.svg\",\n          Loser == \"San Francisco 49ers\" ~ \"https://upload.wikimedia.org/wikipedia/commons/3/3a/San_Francisco_49ers_logo.svg\",\n          Loser == \"Washington Redskins\" ~ \"https://e7.pngegg.com/pngimages/193/260/png-clipart-redskins-logo-red-skins-logo-sports-nfl-football.png\",\n          Loser == \"Chicago Bears\" ~ \"https://upload.wikimedia.org/wikipedia/commons/5/5c/Chicago_Bears_logo.svg\",\n          Loser == \"New York Giants\" ~ \"https://upload.wikimedia.org/wikipedia/commons/6/60/New_York_Giants_logo.svg\",\n          Loser == \"Denver Broncos\" ~ \"https://upload.wikimedia.org/wikipedia/en/4/44/Denver_Broncos_logo.svg\",\n          Loser == \"St. Louis Rams\" ~ \"https://upload.wikimedia.org/wikipedia/en/8/8b/NFL_Rams_logo.svg\",\n           Loser == \"Cincinnati Bengals\" ~ \"https://upload.wikimedia.org/wikipedia/commons/8/81/Cincinnati_Bengals_logo.svg\",\n          Loser == \"New England Patriots\" ~ \"https://upload.wikimedia.org/wikipedia/en/b/b9/New_England_Patriots_logo.svg\",\n           Loser == \"Buffalo Bills\" ~ \"https://upload.wikimedia.org/wikipedia/en/7/77/Buffalo_Bills_logo.svg\",\n          Loser == \"Indianapolis Colts\" ~ \"https://upload.wikimedia.org/wikipedia/commons/0/00/Indianapolis_Colts_logo.svg\",\n           Loser == \"San Diego Chargers\" ~ \"https://upload.wikimedia.org/wikipedia/en/7/72/NFL_Chargers_logo.svg\",\n          Loser == \"Seattle Seahawks\" ~ \"https://upload.wikimedia.org/wikipedia/en/8/8e/Seattle_Seahawks_logo.svg\",\n          Loser == \"Philadelphia Eagles\" ~ \"https://upload.wikimedia.org/wikipedia/en/8/8e/Philadelphia_Eagles_logo.svg\",\n          Loser == \"Atlanta Falcons\" ~ \"https://upload.wikimedia.org/wikipedia/en/c/c5/Atlanta_Falcons_logo.svg\",\n          Loser == \"Tennessee Titans\" ~ \"https://upload.wikimedia.org/wikipedia/en/c/c1/Tennessee_Titans_logo.svg\",\n          Loser == \"Carolina Panthers\" ~ \"https://upload.wikimedia.org/wikipedia/en/1/1c/Carolina_Panthers_logo.svg\",\n          Loser == \"Arizona Cardinals\" ~ \"https://upload.wikimedia.org/wikipedia/en/7/72/Arizona_Cardinals_logo.svg\"\n          )\n       )\n\n# Choosing a subset of columns to display basic information about the Super Bowl\nsuperbowls&lt;-superbowls %&gt;% \n  dplyr::select(\"SB\", \"Date\", \"win_logo_url\", \"Winner\", \"Winning Pts\", \"lose_logo_url\", \"Loser\", \"Losing Pts\", \"City\", \"State\")\n\n# convert to date format\nsuperbowls$Date &lt;- as.Date(superbowls$Date, '%d-%b-%Y') %m+% years(2000) \n# convert to 4 digit year format\nsuperbowls$Date &lt;- dplyr::if_else(superbowls$Date &gt; '2023-01-01', superbowls$Date %m-% years(100), superbowls$Date)\n\n\n# create gt table  \nsuperbowls %&gt;% \n  gt() %&gt;% \n  # add title and subtitle\n  tab_header(\n    title = md(\"**Super Bowl Winners**\"),\n    subtitle = \"Super Bowl I-LII\"\n  ) %&gt;%\n  # format date\n  fmt_date(\n    columns = Date,\n    date_style = 5\n  ) %&gt;%\n  # add winning team label\n  tab_spanner(\n    label = md(\"**Winning Team**\"),\n    columns = c(win_logo_url, Winner, `Winning Pts`)\n  ) %&gt;% \n  # add losing team label\n  tab_spanner(\n    label = \"Losing Team\",\n    columns = c(lose_logo_url, Loser, `Losing Pts`)\n  ) %&gt;% \n  # add location label\n  tab_spanner(\n    label = \"Location\",\n    columns = c(City, State)\n  ) %&gt;% \n  # add super bowl label\n  tab_spanner(\n    label = \"Super Bowl\",\n    columns = c(SB, Date)\n  ) %&gt;% \n  # align the text to center\n  cols_align(\n    align = \"center\") %&gt;% \n  # change names of columns\n  cols_label(\n    SB = \"Number\",\n    Winner = md(\"**Name**\"),\n    `Winning Pts` = md(\"**Points**\"),\n    Loser = \"Name\",\n    `Losing Pts` = \"Points\"\n  ) %&gt;%\n  # convert urls to images\n  text_transform(\n    #Apply a function to a column\n    locations = cells_body(c(win_logo_url, lose_logo_url)),\n    fn = function(x) {\n      #Return an image of set dimensions\n      web_image(\n        url = x,\n        height = 12\n      )\n    }\n  ) %&gt;%\n  #Hide column headers and reduce width\n  cols_width(c(win_logo_url, lose_logo_url) ~ px(30)) %&gt;% \n  cols_label(win_logo_url = \"\") %&gt;% \n  cols_label(lose_logo_url = \"\") %&gt;%\n  # change colors of winning and losing teams\n  tab_style(\n    style = list(\n      cell_fill(\"darkseagreen1\"),\n      cell_text(weight = \"bold\")\n    ),\n    locations = cells_body(\n      columns = c(win_logo_url, Winner, `Winning Pts`)\n    )\n  ) %&gt;% \n  tab_style(\n    style = list(\n      cell_fill(\"#FFADAD\")\n    ),\n    locations = cells_body(\n      columns = c(lose_logo_url, Loser, `Losing Pts`)\n    )\n  ) %&gt;% \n  # add reference footnote\n  tab_source_note(\n    source_note = html(\"Source: &lt;b&gt;Super Bowl Results, Officials, and MVPs&lt;/b&gt;, dataset uploaded by user thedevastator to &lt;a href ='https://www.kaggle.com/datasets/thedevastator/super-bowl-results-officials-and-mvps-1967-2020'&gt;Kaggle.com&lt;/a&gt;.\")\n  )\n\n\n\n\n\n\n\n\nSuper Bowl Winners\n\n\nSuper Bowl I-LII\n\n\n\nSuper Bowl\n\n\nWinning Team\n\n\nLosing Team\n\n\nLocation\n\n\n\nNumber\nDate\n\nName\nPoints\n\nName\nPoints\nCity\nState\n\n\n\n\nI\nJanuary 15, 1967\n\nGreen Bay Packers\n35\n\nKansas City Chiefs\n10\nLos Angeles\nCalifornia\n\n\nII\nJanuary 14, 1968\n\nGreen Bay Packers\n33\n\nOakland Raiders\n14\nMiami\nFlorida\n\n\nIII\nJanuary 12, 1969\n\nNew York Jets\n16\n\nBaltimore Colts\n7\nMiami\nFlorida\n\n\nIV\nJanuary 11, 1970\n\nKansas City Chiefs\n23\n\nMinnesota Vikings\n7\nNew Orleans\nLouisiana\n\n\nV\nJanuary 17, 1971\n\nBaltimore Colts\n16\n\nDallas Cowboys\n13\nMiami\nFlorida\n\n\nVI\nJanuary 16, 1972\n\nDallas Cowboys\n24\n\nMiami Dolphins\n3\nNew Orleans\nLouisiana\n\n\nVII\nJanuary 14, 1973\n\nMiami Dolphins\n14\n\nWashington Redskins\n7\nLos Angeles\nCalifornia\n\n\nVIII\nJanuary 13, 1974\n\nMiami Dolphins\n24\n\nMinnesota Vikings\n7\nHouston\nTexas\n\n\nIX\nJanuary 12, 1975\n\nPittsburgh Steelers\n16\n\nMinnesota Vikings\n6\nNew Orleans\nLouisiana\n\n\nX\nJanuary 18, 1976\n\nPittsburgh Steelers\n21\n\nDallas Cowboys\n17\nMiami\nFlorida\n\n\nXI\nJanuary 9, 1977\n\nOakland Raiders\n32\n\nMinnesota Vikings\n14\nPasadena\nCalifornia\n\n\nXII\nJanuary 15, 1978\n\nDallas Cowboys\n27\n\nDenver Broncos\n10\nNew Orleans\nLouisiana\n\n\nXIII\nJanuary 21, 1979\n\nPittsburgh Steelers\n35\n\nDallas Cowboys\n31\nMiami\nFlorida\n\n\nXIV\nJanuary 20, 1980\n\nPittsburgh Steelers\n31\n\nLos Angeles Rams\n19\nPasadena\nCalifornia\n\n\nXV\nJanuary 25, 1981\n\nOakland Raiders\n27\n\nPhiladelphia Eagles\n10\nNew Orleans\nLouisiana\n\n\nXVI\nJanuary 24, 1982\n\nSan Francisco 49ers\n26\n\nCincinnati Bengals\n21\nPontiac\nMichigan\n\n\nXVII\nJanuary 30, 1983\n\nWashington Redskins\n27\n\nMiami Dolphins\n17\nPasadena\nCalifornia\n\n\nXVIII\nJanuary 22, 1984\n\nLos Angeles Raiders\n38\n\nWashington Redskins\n9\nTampa\nFlorida\n\n\nXIX\nJanuary 20, 1985\n\nSan Francisco 49ers\n38\n\nMiami Dolphins\n16\nPalo Alto\nCalifornia\n\n\nXX\nJanuary 26, 1986\n\nChicago Bears\n46\n\nNew England Patriots\n10\nNew Orleans\nLouisiana\n\n\nXXI\nJanuary 25, 1987\n\nNew York Giants\n39\n\nDenver Broncos\n20\nPasadena\nCalifornia\n\n\nXXII\nJanuary 31, 1988\n\nWashington Redskins\n42\n\nDenver Broncos\n10\nSan Diego\nCalifornia\n\n\nXXIII\nJanuary 22, 1989\n\nSan Francisco 49ers\n20\n\nCincinnati Bengals\n16\nMiami Gardens\nFlorida\n\n\nXXIV\nJanuary 28, 1990\n\nSan Francisco 49ers\n55\n\nDenver Broncos\n10\nNew Orleans\nLouisiana\n\n\nXXV\nJanuary 27, 1991\n\nNew York Giants\n20\n\nBuffalo Bills\n19\nTampa\nFlorida\n\n\nXXVI\nJanuary 26, 1992\n\nWashington Redskins\n37\n\nBuffalo Bills\n24\nMinneapolis\nMinnesota\n\n\nXXVII\nJanuary 31, 1993\n\nDallas Cowboys\n52\n\nBuffalo Bills\n17\nPasadena\nCalifornia\n\n\nXXVIII\nJanuary 30, 1994\n\nDallas Cowboys\n30\n\nBuffalo Bills\n13\nAtlanta\nGeorgia\n\n\nXXIX\nJanuary 29, 1995\n\nSan Francisco 49ers\n49\n\nSan Diego Chargers\n26\nMiami Gardens\nFlorida\n\n\nXXX\nJanuary 28, 1996\n\nDallas Cowboys\n27\n\nPittsburgh Steelers\n17\nTempe\nArizona\n\n\nXXXI\nJanuary 26, 1997\n\nGreen Bay Packers\n35\n\nNew England Patriots\n21\nNew Orleans\nLouisiana\n\n\nXXXII\nJanuary 25, 1998\n\nDenver Broncos\n31\n\nGreen Bay Packers\n24\nSan Diego\nCalifornia\n\n\nXXXIII\nJanuary 31, 1999\n\nDenver Broncos\n34\n\nAtlanta Falcons\n19\nMiami Gardens\nFlorida\n\n\nXXXIV\nJanuary 30, 2000\n\nSt. Louis Rams\n23\n\nTennessee Titans\n16\nAtlanta\nGeorgia\n\n\nXXXV\nJanuary 28, 2001\n\nBaltimore Ravens\n34\n\nNew York Giants\n7\nTampa\nFlorida\n\n\nXXXVI\nFebruary 3, 2002\n\nNew England Patriots\n20\n\nSt. Louis Rams\n17\nNew Orleans\nLouisiana\n\n\nXXXVII\nJanuary 26, 2003\n\nTampa Bay Buccaneers\n48\n\nOakland Raiders\n21\nSan Diego\nCalifornia\n\n\nXXXVIII\nFebruary 1, 2004\n\nNew England Patriots\n32\n\nCarolina Panthers\n29\nHouston\nTexas\n\n\nXXXIX\nFebruary 6, 2005\n\nNew England Patriots\n24\n\nPhiladelphia Eagles\n21\nJacksonville\nFlorida\n\n\nXL\nFebruary 5, 2006\n\nPittsburgh Steelers\n21\n\nSeattle Seahawks\n10\nDetroit\nMichigan\n\n\nXLI\nFebruary 4, 2007\n\nIndianapolis Colts\n29\n\nChicago Bears\n17\nMiami Gardens\nFlorida\n\n\nXLII\nFebruary 3, 2008\n\nNew York Giants\n17\n\nNew England Patriots\n14\nGlendale\nArizona\n\n\nXLIII\nFebruary 1, 2009\n\nPittsburgh Steelers\n27\n\nArizona Cardinals\n23\nTampa\nFlorida\n\n\nXLIV\nFebruary 7, 2010\n\nNew Orleans Saints\n31\n\nIndianapolis Colts\n17\nMiami Gardens\nFlorida\n\n\nXLV\nFebruary 6, 2011\n\nGreen Bay Packers\n31\n\nPittsburgh Steelers\n25\nArlington\nTexas\n\n\nXLVI\nFebruary 5, 2012\n\nNew York Giants\n21\n\nNew England Patriots\n17\nIndianapolis\nIndiana\n\n\nXLVII\nFebruary 3, 2013\n\nBaltimore Ravens\n34\n\nSan Francisco 49ers\n31\nNew Orleans\nLouisiana\n\n\nXLVIII\nFebruary 2, 2014\n\nSeattle Seahawks\n43\n\nDenver Broncos\n8\nEast Rutherford\nNew Jersey\n\n\nXLIX\nFebruary 1, 2015\n\nNew England Patriots\n28\n\nSeattle Seahawks\n24\nGlendale\nArizona\n\n\nL\nFebruary 7, 2016\n\nDenver Broncos\n24\n\nCarolina Panthers\n10\nSanta Clara\nCalifornia\n\n\nLI\nFebruary 5, 2017\n\nNew England Patriots\n34\n\nAtlanta Falcons\n28\nHouston\nTexas\n\n\nLII\nFebruary 4, 2018\n\nPhiladelphia Eagles\n41\n\nNew England Patriots\n33\nMinneapolis\nMinnesota\n\n\n\nSource: Super Bowl Results, Officials, and MVPs, dataset uploaded by user thedevastator to Kaggle.com.\n\n\n\n\n\n\n\n\nAmong the findings, it is disheartening to note that my favorite team, the Cincinnati Bengals, has yet to secure a Super Bowl victory. üò¢ Nevertheless, this revelation adds intrigue and further appreciation for the accomplishments of other teams.\nFeel free to explore the table and discover if your team has clinched the coveted Super Bowl title. Join me in commemorating the remarkable achievements, reliving the defining moments, and reflecting on the enduring legacy of the Super Bowl.\nHas your team ever won?\n\n\n\nOliver F. Anderson, MS ‚Äì Computational Biologist, Data Scientist, and Research Consultant based in Portland, Oregon. I design data-driven solutions in bioinformatics, machine learning, and AI automation for research and biotech. Back to top"
  },
  {
    "objectID": "posts/olympics-tidytuesday.html",
    "href": "posts/olympics-tidytuesday.html",
    "title": "Unveiling Body Compositions in Olympic Track and Field: Exploring Data Trends",
    "section": "",
    "text": "As a passionate track and field athlete, I have always been curious about the correlation between body composition and performance in various events. In this data science project, I explore the realm of Olympic track and field by utilizing data from the Tidy Tuesday GitHub repository (July 27, 2021) to analyze the body compositions of medalists throughout the years.\n\n\nLook at the code\n# load packages and read in data from tidyTuesday\nlibrary(tidyverse)\nlibrary(colorspace)\nlibrary(patchwork)\nlibrary(DT)\nolympics &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-07-27/olympics.csv')\n# head(olympics)\n\n# I am interested in looking at track and field (athletics) medalists\nathletics &lt;- olympics %&gt;% \n  filter(sport==\"Athletics\",\n         !is.na(medal))\n\nathletics$sex &lt;- as.factor(athletics$sex)\n\nathletics_colnames &lt;- c(\"ID\", \"Name\", \"Sex\", \"Age\", \"Height\",\n                        \"Weight\", \"Team\", \"NOC\", \"Games\", \"Year\",\n                        \"Season\", \"City\", \"Sport\", \"Event\",\n                        \"Medal\")\n\nDT::datatable(athletics, colnames = athletics_colnames, caption = htmltools::tags$caption(style = \"caption-side: bottom; text-align: center;\", htmltools::strong(\"Table 1: Olympic Track & Field Medalists\")), filter = \"top\", options = list(pageLength = 5, autoWidth = TRUE))\n\n\n\n\n\n\nAfter filtering the data to focus on track and field medalists, I separated the athletes by sex and visualized their height and weight across different events using informative plots.\n\n\nLook at the code\n# initial exploration\nathletics %&gt;% \n  filter(sex==\"F\") %&gt;% \n  ggplot(aes(height, weight, color=event))+\n  geom_point()\n\n\n\n\n\n\n\n\n\nTo simplify the analysis, I selected representative events and grouped them into categories such as Distance, Mid-Distance, Sprints, Jumps, and Throws. I then refined the visualizations, resulting in a cleaner and more understandable graph.\n\n\nLook at the code\n# there are so many events so lets choose a few events that represent some categories\n# distance: 10k, 5k\n# mid-distance: 800m, 1500m\n# sprints: 100m, 400m\n# jumps: long jump, triple jump\n# throws: shot put, discus, javelin\nathletics$event &lt;- gsub(\"Athletics Women's \", \"\", athletics$event)\nathletics$event &lt;- gsub(\"Athletics Men's \", \"\", athletics$event)\n\nathletics &lt;- athletics %&gt;% \n  filter(event == c(\"10,000 metres\", \"5,000 metres\", \"800 metres\",\"1,500 metres\", \"100 metres\", \"400 metres\", \"Long Jump\", \"Triple Jump\", \"Shot Put\", \"Discus Throw\", \"Javelin Throw\"))\n\nathletics %&gt;% \n  ggplot(aes(height, weight, color=event))+\n  geom_point(alpha=0.5)\n\n\n\n\n\n\n\n\n\nLook at the code\n# this is still too much, let's group them\nathletics &lt;- athletics %&gt;% \n  mutate(event_type = case_when( \n  event %in% c(\"10,000 metres\", \"5,000 metres\") ~ \"Distance\",\n  event %in% c(\"800 metres\",\"1,500 metres\") ~ \"Mid-distance\",\n  event %in% c(\"100 metres\", \"400 metres\") ~ \"Sprints\",\n  event %in% c(\"Long Jump\", \"Triple Jump\", \"High Jump\") ~ \"Jumps\",\n  event %in% c(\"Shot Put\", \"Discus Throw\", \"Javelin Throw\") ~ \"Throws\",\n))\n\n# now it's time to subset by sex\nathletics_f &lt;- athletics %&gt;% \n  filter(sex==\"F\")\n\nathletics_m &lt;- athletics %&gt;% \n  filter(sex==\"M\")\n\n# plot female\nathletics_f %&gt;% \n  ggplot(aes(height, weight, color=event_type))+\n  geom_point(alpha=0.5)\n\n\n\n\n\n\n\n\n\nThis is a much easier graphic to understand so I decided to beautify it.\n\n\nLook at the code\n# putting it together\n(( p1 &lt;- athletics_f %&gt;% \n  ggplot(aes(height, weight, color=event_type))+\n  geom_point(alpha=0.75)+\n  theme_minimal()+\n  scale_color_discrete_qualitative(\"Dark 3\")+\n  labs(title=\"Body Composition of Female \\nOlympic Medalists by Event\\n\", x=\"Height (cm)\", y=\"Weight (kg)\", color=\"Type of Track & Field Event\") ))\n\n\n\n\n\n\n\n\n\nThe findings reveal fascinating trends. Female throwers generally exhibit larger body compositions, both in terms of weight and height, while distance runners tend to be smaller and lighter compared to other athletes. Jumpers, on the other hand, show either tall stature (likely due to high jumpers) or body compositions similar to sprinters. Short sprinters demonstrate a balanced distribution without extreme skewness in either height or weight, while mid-distance runners appear slightly lighter and shorter than their short sprinter counterparts. The sprinters, as a group, exhibit similar body types, with an average height of around 170 cm and weight of 60 kg.\n\n\nLook at the code\n# putting it together\n(( p2 &lt;- athletics_m %&gt;% \n  ggplot(aes(height, weight, color=event_type))+\n  geom_point(alpha=0.75)+\n  theme_minimal()+\n  scale_color_discrete_qualitative(\"Dark 3\")+\n  labs(title=\"Body Composition of Male \\nOlympic Medalists by Event\\n\", x=\"Height (cm)\", y=\"Weight (kg)\", color=\"Type of Track & Field Event\") ))\n\n\n\n\n\n\n\n\n\nSimilar patterns emerge among male Olympic medalists. Throwers dominate the upper right quadrant, indicating their tendency to be taller and heavier than other athletes. Like their female counterparts, male distance runners exhibit lighter and shorter body compositions. Jumpers and sprinters showcase comparable body types, with mid-distance runners falling between short sprinters and distance runners.\nInterestingly, I was surprised to discover that throwers tend to be significantly taller than other athletes, as I initially assumed jumpers would be the tallest, given high jumpers‚Äô requirements. The realization that distance runners tend to be shorter, which hadn‚Äôt caught my attention previously, suggests the importance of the height-to-weight ratio. Being lighter appears advantageous for distance runners, and a shorter stature contributes to achieving this goal.\nThese data align with my observations of track and field events. The trends indicate that specific events attract athletes with distinct body sizes, likely due to inherent advantages associated with their builds. This exploration sheds light on the relationship between body composition and performance, further deepening our understanding of the sport.\nThis project has been illuminating, combining my passion for track and field with data science techniques. Please reach out if you have intriguing project ideas or would like to collaborate. Let‚Äôs embark on compelling data-driven journeys together, unraveling new insights into whatever intrigues you.\n\n\n\nOliver F. Anderson, MS ‚Äì Computational Biologist, Data Scientist, and Research Consultant based in Portland, Oregon. I design data-driven solutions in bioinformatics, machine learning, and AI automation for research and biotech. Back to top"
  },
  {
    "objectID": "posts/sunshine-interactive-visuals.html",
    "href": "posts/sunshine-interactive-visuals.html",
    "title": "Illuminating Insights: Exploring Interactive Graphics with plotly and ggiraph",
    "section": "",
    "text": "In this post, I explore interactive data visualization using the R packages plotly and ggiraph, featuring a dataset on sunshine levels across the U.S. sourced from Kaggle.\nI begin with plotly, creating an interactive line plot that highlights cities of personal significance. Users can double-click cities in the legend to isolate their data for deeper analysis.\nNext, I use ggiraph to build a bar chart comparing cities with similar sunshine levels. An interesting anomaly caught my attention ‚Äî- Los Angeles shows a dip in sunshine during May and June compared to April and July. This raised questions and I aim to investigate further to understand if this pattern is widespread or unique.\nExperimenting with these R packages and the sunshine dataset was rewarding. I hope these visualizations inspire you to explore new destinations for your next sunny getaway.\n\n\nLook at the code\n# load packages and read in data\nlibrary(tidyverse)\nlibrary(ggiraph)\nlibrary(plotly)\nlibrary(ggpubr)\nlibrary(patchwork)\n\nsunshine &lt;- readr::read_csv('./data/avg_sunshine.csv')\n\n# get cities into the right format\nsunshine$CITY &lt;- str_to_title(sunshine$CITY)\nsunshine$CITY &lt;- str_replace(sunshine$CITY, \",\", \", \")\nsunshine$CITY &lt;- gsub(\"(\\\\w$)\", \"\\\\U\\\\1\", sunshine$CITY, perl = TRUE)\n\n# get rid of duplicates\nsunshine &lt;- sunshine %&gt;% \n  filter(CITY != \"CitY\")\n\nsunshine &lt;- sunshine[!duplicated(sunshine$CITY), ]\n\n# get data into the right format\nsunshine &lt;- pivot_longer(sunshine, JAN:DEC, names_to = \"month\", values_to = \"temp\")\n\nsunshine &lt;- sunshine[, -4]\nsunshine$ANN&lt;-as.numeric(sunshine$ANN)\nsunshine$temp&lt;-as.numeric(sunshine$temp)\nsunshine$month&lt;-str_to_title(sunshine$month)\nsunshine$month&lt;-as.factor(sunshine$month)\nsunshine$perc_temp&lt;-sunshine$temp/100\n\n\nsun_cities &lt;- sunshine %&gt;% \n  filter(CITY %in% c(\"Portland, OR\", \"Los Angeles, CA\", \"Honolulu, HI\", \"Chicago, IL\", \"Boston, MA\"))\n\nsun_cities$month &lt;- factor(sun_cities$month, levels=c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"))\n\n\n\n# basic line plot for ggiraph\ngg_sunshine &lt;- sun_cities %&gt;%  \n  ggplot(aes(x = month, y=temp, text = paste0(\"Percent possible sunshine in\\n\",CITY, \": \", temp, \"% in \", month))) +\n  geom_line(aes(x = month, y = temp, color = CITY, group = CITY), alpha=0.8)+\n  labs(x=\"Month\", y=\"Average percent of possible sunshine\", color = \"City\", caption = \"Data from Kaggle.com: uploaded by user thedevastator\", title = \"How sunny are the cities that \\nare important to me?\", subtitle = \"Measured by time of sunshine reaching earth from sunrise to sunset\")+\n  theme_minimal()+\n  theme(\n        plot.title = element_text(vjust = 2),\n        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+\n  scale_y_continuous(labels = scales::percent_format(scale = 1))+\n  scale_color_manual(values=c(\"black\",\"#0454a4\", \"#5688c1\",\"#7ca4d4\", \"#b8cee6\"))\n\nggplotly(gg_sunshine, tooltip = 'text')\n\n\n\n\n\n\nLook at the code\n# working on the ggiraph\n\ntooltip_css &lt;- \"background-color:#7ca4d4;color:white;padding:5px;border-radius:3px;\"\n\navg_sun &lt;- sunshine %&gt;% group_by(CITY, ANN) %&gt;% summarize() %&gt;% na.omit()\n\n# Creating plots\navg_sun$tooltip &lt;- c(paste0(avg_sun$CITY,\": \", avg_sun$ANN, \"%\"))\n\nsun1 &lt;- avg_sun[1:38,] %&gt;% \n  ggplot()+\n  geom_col_interactive(aes(x=reorder(CITY, ANN), y=ANN/100,\n                           tooltip = tooltip,\n                      data_id = ANN), fill=\"#0454a4\")+\n  coord_flip()+\n    labs(x=\"\", y=\"Average annual sunshine\")+\n  theme_minimal()+\n  theme(axis.text.x = element_text(vjust = 2))+\n  lims(y=c(0,1))+\n  scale_y_continuous(labels = scales::percent)+\n  scale_x_discrete(labels=NULL)\n\n\nsun2&lt;-avg_sun[39:76,] %&gt;% \n  ggplot()+\n  geom_col_interactive(aes(x=reorder(CITY, ANN), y=ANN/100,\n                           tooltip = tooltip,\n                      data_id = ANN), fill=\"#0454a4\")+\n  coord_flip()+\n    labs(x=\"\", y=\"Average annual sunshine\")+\n  theme_minimal()+\n  theme(axis.text.x = element_text(vjust = 2))+\n  lims(y=c(0,1))+\n  scale_y_continuous(labels = scales::percent)+\n  scale_x_discrete(labels=NULL)\n\nsun3&lt;-avg_sun[77:115,] %&gt;% \n  ggplot()+\n  geom_col_interactive(aes(x=reorder(CITY, ANN), y=ANN/100,\n                           tooltip = tooltip,\n                      data_id = ANN), fill=\"#0454a4\")+\n  coord_flip()+\n    labs(x=\"\", y=\"Average annual sunshine\")+\n  theme_minimal()+\n  theme(axis.text.x = element_text(vjust = 2))+\n  lims(y=c(0,1))+\n  scale_y_continuous(labels = scales::percent)+\n  scale_x_discrete(labels=NULL)\n\nsun4&lt;-avg_sun[116:153,] %&gt;% \n  ggplot()+\n  geom_col_interactive(aes(x=reorder(CITY, ANN), y=ANN/100,\n                           tooltip = tooltip,\n                      data_id = ANN), fill=\"#0454a4\")+\n  coord_flip()+\n    labs(x=\"\", y=\"Average annual sunshine\")+\n  theme_minimal()+\n  theme(axis.text.x = element_text(vjust = 2))+\n  lims(y=c(0,1))+\n  scale_y_continuous(labels = scales::percent)+\n  scale_x_discrete(labels=NULL)\n\n p&lt;-ggarrange(sun1, sun2, sun3, sun4, ncol=2, nrow=2, labels=c(\"A\",\"B\",\"C\",\"D\"))\ngirafe(\n  code = print(p + plot_annotation(title=\"How sunny is your hometown?\", subtitle = \"Measured by time of sun shine reaching earth from sunrise to sunset\", caption = \"A: Abilene TX - Des Moines, IA\\nB: Detroit, MI - Las Vegas, NV\\nC: Lihue, HI - Providence, RI\\nD: Pueblo, CO - Yap- W Caroline Is., PC\\nData from Kaggle.com: uploaded by user thedevastator\", theme = theme(plot.caption.position = \"plot\", plot.caption = element_text(hjust = 0)))),\n  height_svg = 9,\n  width_svg = NULL,\n  options = list(\n    opts_tooltip(css = tooltip_css, opacity = 1),\n    opts_sizing(width = .7),\n    opts_hover(css = \"fill:#0454a4;stroke-width:2;\"),\n    opts_hover_inv(css = \"opacity:0.1;\"),\n    opts_selection(\n      type = \"single\", \n      only_shiny = FALSE,\n      css = \"fill:#0454a4\"),\n    opts_zoom(max=4)\n  )\n)\n\n\n\n\n\n\n\n\n\nOliver F. Anderson, MS ‚Äì Computational Biologist, Data Scientist, and Research Consultant based in Portland, Oregon. I design data-driven solutions in bioinformatics, machine learning, and AI automation for research and biotech. Back to top"
  },
  {
    "objectID": "posts/city-vacation-planner-shiny.html",
    "href": "posts/city-vacation-planner-shiny.html",
    "title": "City Vacation Planning Shiny App",
    "section": "",
    "text": "&lt;p&gt;Shiny App&lt;/p&gt;\n\n\n\n\n\nOliver F. Anderson, MS ‚Äì Computational Biologist, Data Scientist, and Research Consultant based in Portland, Oregon. I design data-driven solutions in bioinformatics, machine learning, and AI automation for research and biotech. Back to top"
  },
  {
    "objectID": "posts/proteinweaver.html",
    "href": "posts/proteinweaver.html",
    "title": "ProteinWeaver: Visualizing Biological Networks in their Functional Context",
    "section": "",
    "text": "ProteinWeaver is a tool that answers the simple question: How does a particular protein connect to a particular pathway or process? To accomplish this, ProteinWeaver visualizes molecular interaction networks in the context of a user-specified Gene Ontology term. To learn more about ProteinWeaver you can visit the official ProteinWeaver website or the GitHub repository.\n\n\n\nFig. 1 - Screenshot of an example ProteinWeaver query.\n\n\nI am grateful for the opportunity to have worked with Altaf Barelvi and Dr.¬†Anna Ritz on this project.\n\n\n\nOliver F. Anderson, MS ‚Äì Computational Biologist, Data Scientist, and Research Consultant based in Portland, Oregon. I design data-driven solutions in bioinformatics, machine learning, and AI automation for research and biotech. Back to top"
  },
  {
    "objectID": "contact.html#email-icons-png-designed-by-iyikon-photo-by-tyler-lastovich",
    "href": "contact.html#email-icons-png-designed-by-iyikon-photo-by-tyler-lastovich",
    "title": "Contact Me",
    "section": "email icons PNG Designed By IYIKONPhoto by Tyler Lastovich",
    "text": "email icons PNG Designed By IYIKONPhoto by Tyler Lastovich"
  },
  {
    "objectID": "posts/obesity-rates-shiny.html",
    "href": "posts/obesity-rates-shiny.html",
    "title": "Interactive Map in R with Shiny and Leaflet",
    "section": "",
    "text": "This project uses Shiny and Leaflet in R to create an interactive map of CDC data on nutrition, exercise, and obesity across the United States. The app was developed in partnership with Hayden Vaughn and is hosted on shinyapps.io.\nYou can explore the live version here:\nüëâ Full Shiny App\nOliver F. Anderson, MS ‚Äì Computational Biologist, Data Scientist, and Research Consultant based in Portland, Oregon. I design data-driven solutions in bioinformatics, machine learning, and AI automation for research and biotech."
  },
  {
    "objectID": "posts/currency-rates-database.html",
    "href": "posts/currency-rates-database.html",
    "title": "Building a Remote Currency Database with Docker and API Scraping",
    "section": "",
    "text": "Join me on a journey as I delve into database creation, web scraping, and insightful analysis. In this project, I focused on currency exchange rates relative to USD and constructed a robust database by daily scraping from an API. Leveraging Docker containers on Railway.app, I established a remote database for seamless access and comprehensive analysis.\nTo enhance the database, I integrated GDP data by scraping and linking it with currency rates. Additionally, I sourced country names and the currency codes to establish meaningful connections. By importing historical data spanning from the time of GDP growth measurement to my initial API scrape, I gained deeper insights for analysis.\n\n\n\n\nFig 1. - Entity relationship diagram for currency database. Primary keys and linking relationships are shown.\n\n\nWithin the SQL database, I engineered a dynamic View that automatically updated with average monthly currency rates. Equipped with these powerful resources, I conducted an in-depth analysis to identify the fastest growing economies of 2017. However, it‚Äôs crucial to acknowledge that the results were influenced by the recent strength of the dollar. Many currencies exhibited relative underperformance against USD, underscoring the robustness of the dollar in recent times. Notably, the Euro‚Äôs performance, often aligned with the dollar, further illuminated the strengthening trend.\n\n\n\n\nFig 2. - Exchange rates compared to USD for the fastest growing economies of 2017. The US dollar appears to perform well relative to other currencies.\n\n\nThe process of scraping, database creation, and analysis was both enjoyable and rewarding. As a passionate data engineer, I thrive on solving puzzles and ensuring data aligns perfectly with my objectives. I eagerly anticipate undertaking more data engineering projects, pushing boundaries, and uncovering new insights.\nIf you have compelling project ideas or wish to collaborate, please don‚Äôt hesitate to reach out to me. Let‚Äôs embark on captivating data-driven adventures together, unraveling new perspectives in the dynamic world of data engineering.\n\n\n\nOliver F. Anderson, MS ‚Äì Computational Biologist, Data Scientist, and Research Consultant based in Portland, Oregon. I design data-driven solutions in bioinformatics, machine learning, and AI automation for research and biotech. Back to top"
  },
  {
    "objectID": "posts/grphin.html",
    "href": "posts/grphin.html",
    "title": "GRPhIN: Graphlet Characterization of Regulatory and Physical Interaction Networks",
    "section": "",
    "text": "GRPhIN (Graphlet Characterization of Regulatory and Physical Interaction Networks) is an algorithm for counting graphlets and the specific node positions within each graphlet (called orbits) in mixed regulatory and physical interaction networks. Graph representions of regulatory or physical interactions in isolation may obscure the complete functional context of a protein. PPI networks and GRNs do not exist separately; proteins are transcription factors, genes encode proteins, and physical and regulatory interactions mix and coexist forming their own distinct patterns. Graphlets are small, connected, induced subnetworks that describe patterns, local topologies, and organization in networks.\nGRPhIN takes as input (1) an undirected PPI network and (2) a directed regulatory network and counts all mixed graphlets and their respective orbits (Figure 6). GRPhIN provides additional functional context to the roles a protein may play beyond traditional isolated network types.\nLearn more about GRPhIN at the GitHub Repository or read the preprint here. GRPhIN was selected as a full length talk at GLBIO 2025.\n\n\n\n\nScreenshot of ProteinWeaver interface\n\n\n\nFig. 1 - Orbit labeling and graphlet sorting. A) Unique edges and orbit in an RPI graph (orbit 0 indicates a non-edge; orbits 1‚Äì7 are mapped to the five distinct edge types). B) Sorting node orbits in ascending order maintains a unique graphlet structure. C) Sorting isomorphisms result in the same unique set of integer pairs.\n\n\nI am grateful for the opportunity to have worked with Altaf Barelvi and Dr.¬†Anna Ritz on this project and get hands on experience developing algorithms.\n\n\n\nOliver F. Anderson, MS ‚Äì Computational Biologist, Data Scientist, and Research Consultant based in Portland, Oregon. I design data-driven solutions in bioinformatics, machine learning, and AI automation for research and biotech. Back to top"
  },
  {
    "objectID": "posts/rna-seq-data-wrangling.html",
    "href": "posts/rna-seq-data-wrangling.html",
    "title": "Biodegradation of PET Plastic: RNA-seq Analysis and Enzyme Discovery",
    "section": "",
    "text": "This project was the focus of my undergraduate thesis at Willamette University, conducted with Dr.¬†Rosa Le√≥n-Zayas and Grace Sheehan. The goal was to identify enzymes involved in the biodegradation of polyethylene terephthalate (PET) plastic using bioinformatics and RNA-seq analysis.\nOliver F. Anderson, MS ‚Äì Computational Biologist, Data Scientist, and Research Consultant based in Portland, Oregon. I design data-driven solutions in bioinformatics, machine learning, and AI automation for research and biotech."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Oliver F. Anderson, MS",
    "section": "",
    "text": "Oliver F. Anderson, MS ‚Äì Computational Biologist, Data Scientist, and Research Consultant based in Portland, Oregon. I design data-driven solutions in bioinformatics, machine learning, and AI automation for research and biotech."
  },
  {
    "objectID": "index.html#photo-by-xue-guangjian",
    "href": "index.html#photo-by-xue-guangjian",
    "title": "Oliver F. Anderson, MS",
    "section": "Photo by Xue Guangjian",
    "text": "Photo by Xue Guangjian"
  },
  {
    "objectID": "index.html#services-expertise",
    "href": "index.html#services-expertise",
    "title": "Oliver F. Anderson, MS",
    "section": "Services & Expertise",
    "text": "Services & Expertise\n\n\n\nüî¨\n\n\nBioinformatics & Computational Biology\n\nNamespace mapping\nMolecular network visualization\nRNA-Seq & proteomics analysis\nGraph algorithms, motif & interaction analysis\n\n\n\n\n\nüìà\n\n\nData Science & Machine Learning\n\nDatabase design & management\nPredictive models for biological systems\nCustom algorithms for complex datasets\nStatistical analysis & reproducible pipelines\n\n\n\n\n\nüîß\n\n\nAI Automation for Research\n\nWorkflow automation & LLM-powered data parsing\nScientific text mining & knowledge graph building\nCustom research support tools\n\n\n\n\n\nüåê\n\n\nResearch Consulting & Collaboration\n\nData strategy for labs & biotech teams\nCross-disciplinary project design\nTraining & tutoring in computational biology"
  },
  {
    "objectID": "index.html#servicesexpertise",
    "href": "index.html#servicesexpertise",
    "title": "Oliver F. Anderson, MS",
    "section": "Services/Expertise",
    "text": "Services/Expertise\n\nBioinformatics & Computational Biology\n\nProtein network visualization\nGO term and pathway enrichment\nMotif and interaction analysis\n\nData Science & Machine Learning\n\nPredictive models for biological systems\nStatistical analysis & reproducible pipelines\nCustom algorithms for complex datasets\n\nAI Automation for Research\n\nWorkflow automation & LLM-powered data parsing\nScientific text mining and knowledge graph building\nCustom research support tools\n\nResearch Consulting & Collaboration\n\nData strategy for labs and biotech teams\nCross-disciplinary project design\nTraining & tutoring in computational biology\n\n\n          \nPhoto by Xue Guangjian"
  },
  {
    "objectID": "index.html#frequently-asked-questions",
    "href": "index.html#frequently-asked-questions",
    "title": "Oliver F. Anderson, MS",
    "section": "Frequently Asked Questions",
    "text": "Frequently Asked Questions\n\n\n\nWho do you work with?\n\n\nI specialize in computational biology projects, collaborating with academic researchers, biotech startups, and interdisciplinary teams in the life sciences. I also work with small business owners, content creators, and marketers to develop AI-driven automation pipelines and custom support tools across both academic and commercial settings.\n\n\n\n\nWhat kind of data do you analyze?\n\n\nAs a computational biology researcher, I work with protein networks, genomic data (RNA-Seq), GO term annotations, and large biological datasets requiring advanced computational methods for analysis. I also develop custom algorithms and tools to analyze and interpret these data. I work at all stages of the research process, from data collection to analysis and interpretation. See the Services & Expertise section for more details.\n\n\n\n\nDo you offer tutoring or training?\n\n\nYes! I provide mentorship and consulting in computational biology, bioinformatics, and data science methods for students and research groups. I also offer training in AI-driven automation pipelines, scientific text mining, and algorithm development.\n\n\n\n\nWhere are you based?\n\n\nI am based in Portland, Oregon, and available for remote collaborations worldwide."
  },
  {
    "objectID": "index.html#faqs",
    "href": "index.html#faqs",
    "title": "Oliver F. Anderson | Computational Biologist & Data Scientist",
    "section": "FAQs",
    "text": "FAQs\n\n\nWho do you work with?\n\n\nI specialize in computational biology projets, collaborating with academic researchers, biotech startups, and interdisciplinary teams in the life sciences. I also work small business owners, content creators, and marketers to develop AI-driven automation pipelines and custom support tools across both academic and commercial settings.\n\n\n\n\nWhat kind of data do you analyze?\n\n\nAs a computational biology researcher, I work with protein networks, genomic data, GO term annotations, and large biological datasets requiring advanced computational methods. I also develop custom algorithms and tools to analyze and interpret these data. I work at all stages of the research process, from data collection to analysis and interpretation.\n\n\n\n\nDo you offer tutoring or training?\n\n\nYes! I provide mentorship and consulting in computational biology, bioinformatics, and data science methods for students and research groups. I also offer training in AI-driven automation pipelines, scientific text mining, and algorithm development.\n\n\nOliver F. Anderson, MS ‚Äî Computational Biologist, Data Scientist, and Research Consultant based in Portland, Oregon. I design data-driven solutions in bioinformatics, machine learning, and AI automation for research and biotech.\nPhoto by Xue Guangjian"
  },
  {
    "objectID": "index.html#faqs-frequently-asked-questions",
    "href": "index.html#faqs-frequently-asked-questions",
    "title": "Oliver F. Anderson | Computational Biologist & Data Scientist",
    "section": "FAQs (Frequently Asked Questions)",
    "text": "FAQs (Frequently Asked Questions)\n\n\nWho do you work with?\n\n\nI specialize in computational biology projects, collaborating with academic researchers, biotech startups, and interdisciplinary teams in the life sciences. I also work with small business owners, content creators, and marketers to develop AI-driven automation pipelines and custom support tools across both academic and commercial settings.\n\n\n\n\nWhat kind of data do you analyze?\n\n\nAs a computational biology researcher, I work with protein networks, genomic data (RNA-Seq), GO term annotations, and large biological datasets requiring advanced computational methods for analysis. I also develop custom algorithms and tools to analyze and interpret these data. I work at all stages of the research process, from data collection to analysis and interpretation.\n\n\n\n\nDo you offer tutoring or training?\n\n\nYes! I provide mentorship and consulting in computational biology, bioinformatics, and data science methods for students and research groups. I also offer training in AI-driven automation pipelines, scientific text mining, and algorithm development.\n\n\n\nOliver F. Anderson, MS ‚Äî Computational Biologist, Data Scientist, and Research Consultant based in Portland, Oregon. I design data-driven solutions in bioinformatics, machine learning, and AI automation for research and biotech.\n\nPhoto by Xue Guangjian"
  },
  {
    "objectID": "index.html#highlights",
    "href": "index.html#highlights",
    "title": "Oliver F. Anderson | Computational Biologist & Data Scientist",
    "section": "Highlights",
    "text": "Highlights\nüéì Master of Science in Data Science, Willamette University\nüß¨ Research Assistant in Computational Biology, Reed College\nüîó Collaborations across academic research projects and biotech initiatives\nüìÇ Open-source projects and reproducible workflows available on GitHub\nReady to accelerate your research with data-driven insights?\nüëâ Contact Me to discuss collaborations or consulting opportunities."
  },
  {
    "objectID": "index.html#highlighted-work-experience",
    "href": "index.html#highlighted-work-experience",
    "title": "Oliver F. Anderson | Computational Biologist & Data Scientist",
    "section": "Highlighted Work & Experience",
    "text": "Highlighted Work & Experience\n\nüéì Master of Science in Data Science, Willamette University\nüß¨ Research Assistant in Computational Biology, Reed College\nüîó Developed Graphlet Characterization of Regulatory and Physical Interaction Networks (GRPhIN) and ProteinWeaver\nü¶† Developed a pipeline for analyzing RNA-Seq data from a microbial consortium capable of degrading PET plastic\nüìÇ Open-source projects and reproducible workflows available on GitHub\n\nReady to accelerate your research with data-driven insights?\nüëâ Contact Me to discuss collaborations or consulting opportunities."
  },
  {
    "objectID": "index.html#quick-facts",
    "href": "index.html#quick-facts",
    "title": "Oliver F. Anderson, MS",
    "section": "Quick Facts",
    "text": "Quick Facts\n\n\n\n\nAttribute\nDetail\n\n\n\n\nName\nOliver F. Anderson, MS\n\n\nLocation\nPortland, Oregon, USA (remote available)\n\n\nFields\nComputational Biology, Bioinformatics, Data Science, AI Automation\n\n\nEducation\nM.S. in Data Science, Willamette University\n\n\nAffiliations\nReed College, Willamette University\n\n\nExpertise\nProtein networks, GO terms, pathway enrichment, machine learning models, RNA-Seq, AI automation\n\n\nClients\nAcademic researchers, biotech startups, interdisciplinary teams, small businesses\n\n\nWebsite\noliverfanderson.com"
  },
  {
    "objectID": "index.html#highlighted-experience",
    "href": "index.html#highlighted-experience",
    "title": "Oliver F. Anderson | Computational Biologist & Data Scientist",
    "section": "",
    "text": "üéì Master of Science in Data Science, Willamette University\nüß¨ Research Assistant in Computational Biology, Reed College\nüîó Developed Graphlet Characterization of Regulatory and Physical Interaction Networks (GRPhIN) algorithm for counting graphlets in a mixed interaction network\nüï∏ Developed ProteinWeaver web interface for visualizing protein interactions in mixed biological networks\nü¶† Developed a pipeline for analyzing RNA-Seq data from a microbial consortium capable of degrading PET plastic\nüìÇ Open-source projects and reproducible workflows available on GitHub\n\nReady to accelerate your research with data-driven insights?\nüëâ Contact Me to discuss collaborations or consulting opportunities."
  },
  {
    "objectID": "index.html#research-credentials",
    "href": "index.html#research-credentials",
    "title": "Oliver F. Anderson, MS",
    "section": "Research Credentials",
    "text": "Research Credentials\n\nüéì Master of Science in Data Science, Willamette University\nüß¨ Research Assistant in Computational Biology, Reed College"
  },
  {
    "objectID": "index.html#collaborations-projects",
    "href": "index.html#collaborations-projects",
    "title": "Oliver F. Anderson, MS",
    "section": "Collaborations & Projects",
    "text": "Collaborations & Projects\n\nüîó Developed Graphlet Characterization of Regulatory and Physical Interaction Networks (GRPhIN) algorithm for counting graphlets in a mixed interaction network\nüï∏ Developed ProteinWeaver web interface for visualizing protein interactions in mixed biological networks\nü¶† Developed a pipeline for analyzing RNA-Seq data from a microbial consortium capable of degrading PET plastic\nüìÇ Open-source projects and reproducible workflows available on GitHub\n\nReady to accelerate your research with data-driven insights?\nüëâ Contact Me to discuss collaborations or consulting opportunities."
  },
  {
    "objectID": "index.html#about-oliver-f.-anderson",
    "href": "index.html#about-oliver-f.-anderson",
    "title": "Oliver F. Anderson, MS",
    "section": "About Oliver F. Anderson",
    "text": "About Oliver F. Anderson\n\nOliver F. Anderson, MS, is a computational biologist and data scientist specializing in bioinformatics, protein networks, GO term enrichment, and AI-driven data analysis. Based in Portland, Oregon, he collaborates with academic researchers, biotech teams, and interdisciplinary scientists to design algorithms, reproducible workflows, and research automation tools. His work connects biology with machine learning and artificial intelligence, supporting discovery in both academia and industry."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact Me",
    "section": "",
    "text": "Let‚Äôs Connect\n          \n            I am available for collaboration or consultation in data science, computational biology, research software design, and integrating AI automation into your workflows or business. For roles, projects, or lab opportunities, reach out below.\n          \n\n          \n          \n            \n            \n              \n              GitHub\n            \n\n            \n            \n              \n              LinkedIn\n            \n\n            \n            \n              \n              ORCID\n            \n\n            \n            \n              \n              Email\n            \n          \n\n          \n          \n            \n            \n            \n            \n            \n            \n              Don't fill this out if you're human:\n              \n            \n\n            \n              Full Name\n              \n            \n\n            \n              Email address\n              \n            \n\n            \n              Subject\n              \n            \n\n            \n              Organization\n              \n            \n\n            \n              Message\n              \n            \n\n            \n\n            Send Message\n\n            \n            \n              ‚úÖ Thank you! Your message has been sent. I‚Äôll reply shortly.\n            \n          \n\n          \n          \n\n\n          \n          \n            Based in Portland, OR, USA ‚Ä¢ Replies within 2‚Äì3 business days\n          \n\n        \n      \n\n    \n  \n\n\n\n\n\n\n\nOliver F. Anderson, MS ‚Äì Computational Biologist, Data Scientist, and Research Consultant based in Portland, Oregon. I design data-driven solutions in bioinformatics, machine learning, and AI automation for research and biotech. Back to top"
  },
  {
    "objectID": "index.html#computational-biology-data-science-solutions-for-research",
    "href": "index.html#computational-biology-data-science-solutions-for-research",
    "title": "Oliver F. Anderson, MS",
    "section": "Computational Biology & Data Science Solutions for Research",
    "text": "Computational Biology & Data Science Solutions for Research\nI‚Äôm Oliver F. Anderson, MS, a computational biologist and data scientist helping researchers, labs, and biotech teams transform complex biological data into actionable discoveries.\n\n üîç View Projects  üì¨ Work With Me\n\nWith a background in bioinformatics, protein network analysis, and AI-driven automation pipelines, I specialize in building tools that accelerate discovery in the life sciences. My work bridges biology, machine learning, and automation, supporting both academic research and biotech innovation."
  },
  {
    "objectID": "index.html#about-oliver-f.-anderson-ms",
    "href": "index.html#about-oliver-f.-anderson-ms",
    "title": "Oliver F. Anderson, MS",
    "section": "About Oliver F. Anderson, MS",
    "text": "About Oliver F. Anderson, MS\n\nOliver F. Anderson, MS, is a computational biologist and data scientist specializing in bioinformatics, protein networks, GO term enrichment, data analysis, and AI-driven automation. Based in Portland, Oregon, he collaborates with academic researchers, biotech teams, and interdisciplinary scientists to design algorithms, reproducible workflows, and research automation tools. His work connects biology with machine learning and artificial intelligence, supporting discovery in both academia and industry."
  },
  {
    "objectID": "about.html#frequently-asked-questions",
    "href": "about.html#frequently-asked-questions",
    "title": "About Oliver F. Anderson, MS",
    "section": "Frequently Asked Questions",
    "text": "Frequently Asked Questions\n\n\n\nWhat is GRPhIN and how does it advance network biology?\n\n\nGRPhIN (Graphlet Characterization of Regulatory and Physical Interaction Networks) is an algorithm Oliver developed to analyze 3-node graphlet distributions in mixed biological networks. It provides insights into structural patterns of protein and gene interactions, helping researchers uncover regulatory, physical, and mixed motifs, and functional relationships.\n\n\n\n\nWhat is ProteinWeaver and how can researchers use it?\n\n\nProteinWeaver is a web-based platform Oliver developed to visualize molecular interaction networks in the context of Gene Ontology (GO) terms. It allows researchers to explore molecular pathways, mixed-interaction motifs, and gene-protein relationships within specific biological contexts.\n\n\n\n\nWhat programming languages and tools do you use in computational biology?\n\n\nOliver works across a wide tech stack, including Python, R, JavaScript, SQL/Cypher, and bash for algorithm and full-stack development, alongside bioinformatics pipelines such as FastQC, BowTie, Samtools, FeatureCounts, BLAST, and Bioconductor. He also applies Snakemake, Docker, graph algorithms, and machine learning for scalable data analysis and software engineering.\n\n\n\n\nWhat are network motifs and why are they significant in biology?\n\n\nNetwork motifs are recurring subnetwork patterns that reveal functional building blocks of complex biological systems. Studying motifs helps researchers understand cellular signaling, regulatory and physical interactions networks, and evolutionary design principles.\n\n\n\n\nWhat are your main research publications?\n\n\n\nBioinformatics Advances (2025) on the GRPhIN algorithm\nPLOS ONE (2025) on ProteinWeaver\nInternational Journal of Molecular Sciences (2022) on RNA sequencing pipelines\n\n\n\n\n\nAre you open to collaborations or PhD opportunities?\n\n\nYes! Oliver is based in Portland, Oregon and open to remote collaborations, industry opportunities, and PhD programs in computational biology, bioinformatics, and data science. He has a special interest in the human microbiome, specifically in the gut-brain axis and how microbial communities impact human mood and cognition. In addition to his computational expertise, he has experience working in wet-lab settings."
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Below is a complete list of my academic publications.\nYou can click the buttons under each entry to view the journal page or download the citation. More information about the work in these publications is available on the projects page.\n\n\n\n1. Edwards S, Le√≥n-Zayas R, Ditter R, Laster H, Sheehan G, Anderson O, et al. Microbial Consortia and Mixed Plastic Waste: Pangenomic Analysis Reveals Potential for Degradation of Multiple Plastic Types via Previously Identified PET Degrading Bacteria. International Journal of Molecular Sciences [Internet]. 2022 May;23(10):5612. Available from: https://doi.org/10.3390/ijms23105612\n\n\n2. Barelvi A, Anderson O, Ritz A. GRPhIN: Graphlet characterization of regulatory and physical interaction networks. Bioinformatics Advances [Internet]. 2025 Jul;5(1):vbaf176. Available from: https://doi.org/10.1093/bioadv/vbaf176\n\n\n3. Anderson O, Barelvi A, O‚ÄôBrien A, Norman A, Jan I, Ritz A. ProteinWeaver: A webtool to visualize ontology-annotated protein networks. PLOS ONE [Internet]. 2025 Sep;20(9):e0331280. Available from: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0331280\n\n\n\n\n\n\n\nOliver F. Anderson, MS ‚Äì Computational Biologist, Data Scientist, and Research Consultant based in Portland, Oregon. I design data-driven solutions in bioinformatics, machine learning, and AI automation for research and biotech. Back to top"
  },
  {
    "objectID": "publications.html#publications",
    "href": "publications.html#publications",
    "title": "Publications",
    "section": "",
    "text": "Below is a complete list of my academic publications.\nYou can click the buttons under each entry to view the journal page or download the citation.\n\n\n\n1. Edwards S, Le√≥n-Zayas R, Ditter R, Laster H, Sheehan G, Anderson O, et al. Microbial Consortia and Mixed Plastic Waste: Pangenomic Analysis Reveals Potential for Degradation of Multiple Plastic Types via Previously Identified PET Degrading Bacteria. International Journal of Molecular Sciences [Internet]. 2022 Jan [cited 2025 Aug 22];23(10):5612. Available from: https://www.mdpi.com/1422-0067/23/10/5612\n\n\n2. Barelvi A, Anderson O, Ritz A. GRPhIN: Graphlet characterization of regulatory and physical interaction networks. Bioinformatics Advances [Internet]. 2025 Jan [cited 2025 Aug 22];5(1):vbaf176. Available from: https://doi.org/10.1093/bioadv/vbaf176\n\n\n3. Anderson O, Barelvi A, O‚ÄôBrien A, Norman A, Jan I, Ritz A. ProteinWeaver: A Webtool to Visualize Ontology-Annotated Protein Networks [Internet]. bioRxiv; 2024 [cited 2025 Aug 22]. Available from: https://www.biorxiv.org/content/10.1101/2024.10.24.620032v2"
  },
  {
    "objectID": "posts/super-bowl-champions-r-gt-table.html",
    "href": "posts/super-bowl-champions-r-gt-table.html",
    "title": "Super Bowl Champions: Analysis Using the gt R Package",
    "section": "",
    "text": "For the 2023 Super Bowl, I used the gt package in R to build a formatted table of all past champions. The goal was to present the history of the game in a clean, reproducible way, while demonstrating how gt can handle images, formatting, and export.\nOliver F. Anderson, MS ‚Äì Computational Biologist, Data Scientist, and Research Consultant based in Portland, Oregon. I design data-driven solutions in bioinformatics, machine learning, and AI automation for research and biotech."
  },
  {
    "objectID": "posts/super-bowl-champions-r-gt-table.html#super-bowl-champions-in-r-with-gt",
    "href": "posts/super-bowl-champions-r-gt-table.html#super-bowl-champions-in-r-with-gt",
    "title": "Super Bowl Champions: Analysis Using the gt R Package",
    "section": "",
    "text": "For the 2023 Super Bowl, I used the gt package in R to build a formatted table of all past champions. The goal was to present the history of the game in a clean, reproducible way, while demonstrating how gt can handle images, formatting, and export.\n\n\n\nLoad and prepare the data\n\nImported a Super Bowl dataset (winners, losers, scores, dates, host cities).\n\nAdded a column of team logo URLs.\n\nApplied as.Date() and conditional year formatting to create a consistent date format.\n\n\nFormat with gt\n\nHighlighted the game number, date, teams, scores, and location.\n\nUsed text_transform() and web_image() to render team logos.\n\nCreated aesthetic labels and spanners for winning and losing teams.\n\nApplied fmt_date() for aesthetic date formatting.\n\n\nExport the final table\n\nSaved the result as PNG for social preview image.\n\n\n\n\n\n\n\nLook at the code\n# load packages and read in data\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(lubridate)\n\nsuperbowls &lt;- readr::read_csv('./data/Super_Bowl.csv')\n \n# add logos for each team\nsuperbowls &lt;- superbowls %&gt;% \n  mutate(win_logo_url = \n  case_when(\n          Winner == \"Green Bay Packers\" ~ \"https://upload.wikimedia.org/wikipedia/commons/5/50/Green_Bay_Packers_logo.svg\",\n          Winner == \"New York Jets\" ~ \"https://upload.wikimedia.org/wikipedia/en/6/6b/New_York_Jets_logo.svg\",\n          Winner == \"Kansas City Chiefs\" ~ \"https://upload.wikimedia.org/wikipedia/en/e/e1/Kansas_City_Chiefs_logo.svg\",\n          Winner == \"Baltimore Colts\" ~ \"https://upload.wikimedia.org/wikipedia/en/1/1f/Baltimore_Colts_logo_1961-1978.gif\",\n          Winner == \"Dallas Cowboys\" ~ \"https://upload.wikimedia.org/wikipedia/commons/1/15/Dallas_Cowboys.svg\",\n          Winner == \"Miami Dolphins\" ~ \"https://upload.wikimedia.org/wikipedia/en/3/37/Miami_Dolphins_logo.svg\",\n          Winner == \"Pittsburgh Steelers\" ~ \"https://upload.wikimedia.org/wikipedia/commons/d/de/Pittsburgh_Steelers_logo.svg\",\n          Winner == \"Oakland Raiders\" ~ \"https://upload.wikimedia.org/wikipedia/en/4/48/Las_Vegas_Raiders_logo.svg\",\n          Winner == \"Los Angeles Raiders\" ~ \"https://upload.wikimedia.org/wikipedia/en/4/48/Las_Vegas_Raiders_logo.svg\",\n          Winner == \"San Francisco 49ers\" ~ \"https://upload.wikimedia.org/wikipedia/commons/3/3a/San_Francisco_49ers_logo.svg\",\n          Winner == \"Washington Redskins\" ~ \"https://e7.pngegg.com/pngimages/193/260/png-clipart-redskins-logo-red-skins-logo-sports-nfl-football.png\",\n          Winner == \"Chicago Bears\" ~ \"https://upload.wikimedia.org/wikipedia/commons/5/5c/Chicago_Bears_logo.svg\",\n          Winner == \"New York Giants\" ~ \"https://upload.wikimedia.org/wikipedia/commons/6/60/New_York_Giants_logo.svg\",\n          Winner == \"Denver Broncos\" ~ \"https://upload.wikimedia.org/wikipedia/en/4/44/Denver_Broncos_logo.svg\",\n          Winner == \"St. Louis Rams\" ~ \"https://upload.wikimedia.org/wikipedia/en/8/8b/NFL_Rams_logo.svg\",\n          Winner == \"Baltimore Ravens\" ~ \"https://upload.wikimedia.org/wikipedia/en/1/16/Baltimore_Ravens_logo.svg\",\n          Winner == \"New England Patriots\" ~ \"https://upload.wikimedia.org/wikipedia/en/b/b9/New_England_Patriots_logo.svg\",\n          Winner == \"Tampa Bay Buccaneers\" ~ \"https://upload.wikimedia.org/wikipedia/en/a/a2/Tampa_Bay_Buccaneers_logo.svg\",\n          Winner == \"Indianapolis Colts\" ~ \"https://upload.wikimedia.org/wikipedia/commons/0/00/Indianapolis_Colts_logo.svg\",\n          Winner == \"New Orleans Saints\" ~ \"https://upload.wikimedia.org/wikipedia/commons/5/50/New_Orleans_Saints_logo.svg\",\n          Winner == \"Seattle Seahawks\" ~ \"https://upload.wikimedia.org/wikipedia/en/8/8e/Seattle_Seahawks_logo.svg\",\n          Winner == \"Philadelphia Eagles\" ~ \"https://upload.wikimedia.org/wikipedia/en/8/8e/Philadelphia_Eagles_logo.svg\"\n          )\n       ) %&gt;% \n  mutate(lose_logo_url = \n  case_when(\n          Loser == \"Green Bay Packers\" ~ \"https://upload.wikimedia.org/wikipedia/commons/5/50/Green_Bay_Packers_logo.svg\",\n            Loser == \"Minnesota Vikings\" ~ \"https://upload.wikimedia.org/wikipedia/en/4/48/Minnesota_Vikings_logo.svg\",\n          Loser == \"Kansas City Chiefs\" ~ \"https://upload.wikimedia.org/wikipedia/en/e/e1/Kansas_City_Chiefs_logo.svg\",\n          Loser == \"Baltimore Colts\" ~ \"https://upload.wikimedia.org/wikipedia/en/1/1f/Baltimore_Colts_logo_1961-1978.gif\",\n          Loser == \"Dallas Cowboys\" ~ \"https://upload.wikimedia.org/wikipedia/commons/1/15/Dallas_Cowboys.svg\",\n          Loser == \"Miami Dolphins\" ~ \"https://upload.wikimedia.org/wikipedia/en/3/37/Miami_Dolphins_logo.svg\",\n          Loser == \"Pittsburgh Steelers\" ~ \"https://upload.wikimedia.org/wikipedia/commons/d/de/Pittsburgh_Steelers_logo.svg\",\n          Loser == \"Oakland Raiders\" ~ \"https://upload.wikimedia.org/wikipedia/en/4/48/Las_Vegas_Raiders_logo.svg\",\n          Loser == \"Los Angeles Rams\" ~ \"https://upload.wikimedia.org/wikipedia/en/8/8a/Los_Angeles_Rams_logo.svg\",\n          Loser == \"San Francisco 49ers\" ~ \"https://upload.wikimedia.org/wikipedia/commons/3/3a/San_Francisco_49ers_logo.svg\",\n          Loser == \"Washington Redskins\" ~ \"https://e7.pngegg.com/pngimages/193/260/png-clipart-redskins-logo-red-skins-logo-sports-nfl-football.png\",\n          Loser == \"Chicago Bears\" ~ \"https://upload.wikimedia.org/wikipedia/commons/5/5c/Chicago_Bears_logo.svg\",\n          Loser == \"New York Giants\" ~ \"https://upload.wikimedia.org/wikipedia/commons/6/60/New_York_Giants_logo.svg\",\n          Loser == \"Denver Broncos\" ~ \"https://upload.wikimedia.org/wikipedia/en/4/44/Denver_Broncos_logo.svg\",\n          Loser == \"St. Louis Rams\" ~ \"https://upload.wikimedia.org/wikipedia/en/8/8b/NFL_Rams_logo.svg\",\n           Loser == \"Cincinnati Bengals\" ~ \"https://upload.wikimedia.org/wikipedia/commons/8/81/Cincinnati_Bengals_logo.svg\",\n          Loser == \"New England Patriots\" ~ \"https://upload.wikimedia.org/wikipedia/en/b/b9/New_England_Patriots_logo.svg\",\n           Loser == \"Buffalo Bills\" ~ \"https://upload.wikimedia.org/wikipedia/en/7/77/Buffalo_Bills_logo.svg\",\n          Loser == \"Indianapolis Colts\" ~ \"https://upload.wikimedia.org/wikipedia/commons/0/00/Indianapolis_Colts_logo.svg\",\n           Loser == \"San Diego Chargers\" ~ \"https://upload.wikimedia.org/wikipedia/en/7/72/NFL_Chargers_logo.svg\",\n          Loser == \"Seattle Seahawks\" ~ \"https://upload.wikimedia.org/wikipedia/en/8/8e/Seattle_Seahawks_logo.svg\",\n          Loser == \"Philadelphia Eagles\" ~ \"https://upload.wikimedia.org/wikipedia/en/8/8e/Philadelphia_Eagles_logo.svg\",\n          Loser == \"Atlanta Falcons\" ~ \"https://upload.wikimedia.org/wikipedia/en/c/c5/Atlanta_Falcons_logo.svg\",\n          Loser == \"Tennessee Titans\" ~ \"https://upload.wikimedia.org/wikipedia/en/c/c1/Tennessee_Titans_logo.svg\",\n          Loser == \"Carolina Panthers\" ~ \"https://upload.wikimedia.org/wikipedia/en/1/1c/Carolina_Panthers_logo.svg\",\n          Loser == \"Arizona Cardinals\" ~ \"https://upload.wikimedia.org/wikipedia/en/7/72/Arizona_Cardinals_logo.svg\"\n          )\n       )\n\n# Choosing a subset of columns to display basic information about the Super Bowl\nsuperbowls&lt;-superbowls %&gt;% \n  dplyr::select(\"SB\", \"Date\", \"win_logo_url\", \"Winner\", \"Winning Pts\", \"lose_logo_url\", \"Loser\", \"Losing Pts\", \"City\", \"State\")\n\n# convert to date format\nsuperbowls$Date &lt;- as.Date(superbowls$Date, '%d-%b-%Y') %m+% years(2000) \n# convert to 4 digit year format\nsuperbowls$Date &lt;- dplyr::if_else(superbowls$Date &gt; '2023-01-01', superbowls$Date %m-% years(100), superbowls$Date)\n\n\n# create gt table  \nsuperbowls %&gt;% \n  gt() %&gt;% \n  # add title and subtitle\n  tab_header(\n    title = md(\"**Super Bowl Winners**\"),\n    subtitle = \"Super Bowl I-LII\"\n  ) %&gt;%\n  # format date\n  fmt_date(\n    columns = Date,\n    date_style = 5\n  ) %&gt;%\n  # add winning team label\n  tab_spanner(\n    label = md(\"**Winning Team**\"),\n    columns = c(win_logo_url, Winner, `Winning Pts`)\n  ) %&gt;% \n  # add losing team label\n  tab_spanner(\n    label = \"Losing Team\",\n    columns = c(lose_logo_url, Loser, `Losing Pts`)\n  ) %&gt;% \n  # add location label\n  tab_spanner(\n    label = \"Location\",\n    columns = c(City, State)\n  ) %&gt;% \n  # add super bowl label\n  tab_spanner(\n    label = \"Super Bowl\",\n    columns = c(SB, Date)\n  ) %&gt;% \n  # align the text to center\n  cols_align(\n    align = \"center\") %&gt;% \n  # change names of columns\n  cols_label(\n    SB = \"Number\",\n    Winner = md(\"**Name**\"),\n    `Winning Pts` = md(\"**Points**\"),\n    Loser = \"Name\",\n    `Losing Pts` = \"Points\"\n  ) %&gt;%\n  # convert urls to images\n  text_transform(\n    #Apply a function to a column\n    locations = cells_body(c(win_logo_url, lose_logo_url)),\n    fn = function(x) {\n      #Return an image of set dimensions\n      web_image(\n        url = x,\n        height = 15\n      )\n    }\n  ) %&gt;%\n  #Hide column headers and reduce width\n  cols_width(c(win_logo_url, lose_logo_url) ~ px(30)) %&gt;% \n  cols_label(win_logo_url = \"\") %&gt;% \n  cols_label(lose_logo_url = \"\") %&gt;%\n  # change colors of winning and losing teams\n  tab_style(\n    style = list(\n      cell_fill(\"darkseagreen1\"),\n      cell_text(weight = \"bold\")\n    ),\n    locations = cells_body(\n      columns = c(win_logo_url, Winner, `Winning Pts`)\n    )\n  ) %&gt;% \n  tab_style(\n    style = list(\n      cell_fill(\"#FFADAD\")\n    ),\n    locations = cells_body(\n      columns = c(lose_logo_url, Loser, `Losing Pts`)\n    )\n  ) %&gt;% \n  # add reference footnote\n  tab_source_note(\n    source_note = html(\"Source: &lt;b&gt;Super Bowl Results, Officials, and MVPs&lt;/b&gt;, dataset uploaded by user thedevastator to &lt;a href ='https://www.kaggle.com/datasets/thedevastator/super-bowl-results-officials-and-mvps-1967-2020'&gt;Kaggle.com&lt;/a&gt;.\")\n  )\n\n\n\n\n\n\n\n\nSuper Bowl Winners\n\n\nSuper Bowl I-LII\n\n\n\nSuper Bowl\n\n\nWinning Team\n\n\nLosing Team\n\n\nLocation\n\n\n\nNumber\nDate\n\nName\nPoints\n\nName\nPoints\nCity\nState\n\n\n\n\nI\nJanuary 15, 1967\n\nGreen Bay Packers\n35\n\nKansas City Chiefs\n10\nLos Angeles\nCalifornia\n\n\nII\nJanuary 14, 1968\n\nGreen Bay Packers\n33\n\nOakland Raiders\n14\nMiami\nFlorida\n\n\nIII\nJanuary 12, 1969\n\nNew York Jets\n16\n\nBaltimore Colts\n7\nMiami\nFlorida\n\n\nIV\nJanuary 11, 1970\n\nKansas City Chiefs\n23\n\nMinnesota Vikings\n7\nNew Orleans\nLouisiana\n\n\nV\nJanuary 17, 1971\n\nBaltimore Colts\n16\n\nDallas Cowboys\n13\nMiami\nFlorida\n\n\nVI\nJanuary 16, 1972\n\nDallas Cowboys\n24\n\nMiami Dolphins\n3\nNew Orleans\nLouisiana\n\n\nVII\nJanuary 14, 1973\n\nMiami Dolphins\n14\n\nWashington Redskins\n7\nLos Angeles\nCalifornia\n\n\nVIII\nJanuary 13, 1974\n\nMiami Dolphins\n24\n\nMinnesota Vikings\n7\nHouston\nTexas\n\n\nIX\nJanuary 12, 1975\n\nPittsburgh Steelers\n16\n\nMinnesota Vikings\n6\nNew Orleans\nLouisiana\n\n\nX\nJanuary 18, 1976\n\nPittsburgh Steelers\n21\n\nDallas Cowboys\n17\nMiami\nFlorida\n\n\nXI\nJanuary 9, 1977\n\nOakland Raiders\n32\n\nMinnesota Vikings\n14\nPasadena\nCalifornia\n\n\nXII\nJanuary 15, 1978\n\nDallas Cowboys\n27\n\nDenver Broncos\n10\nNew Orleans\nLouisiana\n\n\nXIII\nJanuary 21, 1979\n\nPittsburgh Steelers\n35\n\nDallas Cowboys\n31\nMiami\nFlorida\n\n\nXIV\nJanuary 20, 1980\n\nPittsburgh Steelers\n31\n\nLos Angeles Rams\n19\nPasadena\nCalifornia\n\n\nXV\nJanuary 25, 1981\n\nOakland Raiders\n27\n\nPhiladelphia Eagles\n10\nNew Orleans\nLouisiana\n\n\nXVI\nJanuary 24, 1982\n\nSan Francisco 49ers\n26\n\nCincinnati Bengals\n21\nPontiac\nMichigan\n\n\nXVII\nJanuary 30, 1983\n\nWashington Redskins\n27\n\nMiami Dolphins\n17\nPasadena\nCalifornia\n\n\nXVIII\nJanuary 22, 1984\n\nLos Angeles Raiders\n38\n\nWashington Redskins\n9\nTampa\nFlorida\n\n\nXIX\nJanuary 20, 1985\n\nSan Francisco 49ers\n38\n\nMiami Dolphins\n16\nPalo Alto\nCalifornia\n\n\nXX\nJanuary 26, 1986\n\nChicago Bears\n46\n\nNew England Patriots\n10\nNew Orleans\nLouisiana\n\n\nXXI\nJanuary 25, 1987\n\nNew York Giants\n39\n\nDenver Broncos\n20\nPasadena\nCalifornia\n\n\nXXII\nJanuary 31, 1988\n\nWashington Redskins\n42\n\nDenver Broncos\n10\nSan Diego\nCalifornia\n\n\nXXIII\nJanuary 22, 1989\n\nSan Francisco 49ers\n20\n\nCincinnati Bengals\n16\nMiami Gardens\nFlorida\n\n\nXXIV\nJanuary 28, 1990\n\nSan Francisco 49ers\n55\n\nDenver Broncos\n10\nNew Orleans\nLouisiana\n\n\nXXV\nJanuary 27, 1991\n\nNew York Giants\n20\n\nBuffalo Bills\n19\nTampa\nFlorida\n\n\nXXVI\nJanuary 26, 1992\n\nWashington Redskins\n37\n\nBuffalo Bills\n24\nMinneapolis\nMinnesota\n\n\nXXVII\nJanuary 31, 1993\n\nDallas Cowboys\n52\n\nBuffalo Bills\n17\nPasadena\nCalifornia\n\n\nXXVIII\nJanuary 30, 1994\n\nDallas Cowboys\n30\n\nBuffalo Bills\n13\nAtlanta\nGeorgia\n\n\nXXIX\nJanuary 29, 1995\n\nSan Francisco 49ers\n49\n\nSan Diego Chargers\n26\nMiami Gardens\nFlorida\n\n\nXXX\nJanuary 28, 1996\n\nDallas Cowboys\n27\n\nPittsburgh Steelers\n17\nTempe\nArizona\n\n\nXXXI\nJanuary 26, 1997\n\nGreen Bay Packers\n35\n\nNew England Patriots\n21\nNew Orleans\nLouisiana\n\n\nXXXII\nJanuary 25, 1998\n\nDenver Broncos\n31\n\nGreen Bay Packers\n24\nSan Diego\nCalifornia\n\n\nXXXIII\nJanuary 31, 1999\n\nDenver Broncos\n34\n\nAtlanta Falcons\n19\nMiami Gardens\nFlorida\n\n\nXXXIV\nJanuary 30, 2000\n\nSt. Louis Rams\n23\n\nTennessee Titans\n16\nAtlanta\nGeorgia\n\n\nXXXV\nJanuary 28, 2001\n\nBaltimore Ravens\n34\n\nNew York Giants\n7\nTampa\nFlorida\n\n\nXXXVI\nFebruary 3, 2002\n\nNew England Patriots\n20\n\nSt. Louis Rams\n17\nNew Orleans\nLouisiana\n\n\nXXXVII\nJanuary 26, 2003\n\nTampa Bay Buccaneers\n48\n\nOakland Raiders\n21\nSan Diego\nCalifornia\n\n\nXXXVIII\nFebruary 1, 2004\n\nNew England Patriots\n32\n\nCarolina Panthers\n29\nHouston\nTexas\n\n\nXXXIX\nFebruary 6, 2005\n\nNew England Patriots\n24\n\nPhiladelphia Eagles\n21\nJacksonville\nFlorida\n\n\nXL\nFebruary 5, 2006\n\nPittsburgh Steelers\n21\n\nSeattle Seahawks\n10\nDetroit\nMichigan\n\n\nXLI\nFebruary 4, 2007\n\nIndianapolis Colts\n29\n\nChicago Bears\n17\nMiami Gardens\nFlorida\n\n\nXLII\nFebruary 3, 2008\n\nNew York Giants\n17\n\nNew England Patriots\n14\nGlendale\nArizona\n\n\nXLIII\nFebruary 1, 2009\n\nPittsburgh Steelers\n27\n\nArizona Cardinals\n23\nTampa\nFlorida\n\n\nXLIV\nFebruary 7, 2010\n\nNew Orleans Saints\n31\n\nIndianapolis Colts\n17\nMiami Gardens\nFlorida\n\n\nXLV\nFebruary 6, 2011\n\nGreen Bay Packers\n31\n\nPittsburgh Steelers\n25\nArlington\nTexas\n\n\nXLVI\nFebruary 5, 2012\n\nNew York Giants\n21\n\nNew England Patriots\n17\nIndianapolis\nIndiana\n\n\nXLVII\nFebruary 3, 2013\n\nBaltimore Ravens\n34\n\nSan Francisco 49ers\n31\nNew Orleans\nLouisiana\n\n\nXLVIII\nFebruary 2, 2014\n\nSeattle Seahawks\n43\n\nDenver Broncos\n8\nEast Rutherford\nNew Jersey\n\n\nXLIX\nFebruary 1, 2015\n\nNew England Patriots\n28\n\nSeattle Seahawks\n24\nGlendale\nArizona\n\n\nL\nFebruary 7, 2016\n\nDenver Broncos\n24\n\nCarolina Panthers\n10\nSanta Clara\nCalifornia\n\n\nLI\nFebruary 5, 2017\n\nNew England Patriots\n34\n\nAtlanta Falcons\n28\nHouston\nTexas\n\n\nLII\nFebruary 4, 2018\n\nPhiladelphia Eagles\n41\n\nNew England Patriots\n33\nMinneapolis\nMinnesota\n\n\n\nSource: Super Bowl Results, Officials, and MVPs, dataset uploaded by user thedevastator to Kaggle.com.\n\n\n\n\n\n\n\n\n\n\n\nThe finished table shows every champion (as of 2023) since the first Super Bowl, along with team logos, scores, and host cities. It provides a quick way to explore the history of the event while highlighting the flexibility of gt.\nAs a Bengals fan, I noticed they‚Äôre still waiting for their first title üòÖ. That aside, the table offers a comprehensive view of the NFL‚Äôs biggest stage and is an example of how gt can be used to create effective visualizations in sports analytics projects.\n\n\n\n\n\n\nHow do I add images or team logos to a gt table in R?\n\n\nUse text_transform() with web_image() or local_image() to replace text with logos in your table.\n\n\n\n\nHow can I format dates and scores in gt?\n\n\nFunctions like fmt_date() and fmt_number() control display formats while keeping raw data intact.\n\n\n\n\nCan I export a gt table to share outside of R?\n\n\nYes. Use gtsave() to export to HTML, PNG, or PDF.\n\n\n\n\nIs gt only for sports data?\n\n\nNo.¬†gt works well for any structured dataset‚Äîfinance, education, scientific research, and more."
  },
  {
    "objectID": "posts/interactive-visualization-r-plotly-ggiraph.html",
    "href": "posts/interactive-visualization-r-plotly-ggiraph.html",
    "title": "Interactive Data Visualization in R with plotly and ggiraph",
    "section": "",
    "text": "This project demonstrates how to create interactive plots in R using the plotly and ggiraph packages. The dataset comes from Kaggle, which reports the percentage of possible sunshine across major U.S. cities.\nThe goal was twofold:\n- Use plotly to create a line plot where users can isolate individual cities for closer inspection.\n- Use ggiraph to produce interactive bar charts that compare annual sunshine levels across cities.\nOliver F. Anderson, MS ‚Äì Computational Biologist, Data Scientist, and Research Consultant based in Portland, Oregon. I design data-driven solutions in bioinformatics, machine learning, and AI automation for research and biotech."
  },
  {
    "objectID": "posts/interactive-visualization-r-plotly-ggiraph.html#interactive-data-visualization-in-r-with-plotly-and-ggiraph",
    "href": "posts/interactive-visualization-r-plotly-ggiraph.html#interactive-data-visualization-in-r-with-plotly-and-ggiraph",
    "title": "Interactive Data Visualization in R with plotly and ggiraph",
    "section": "",
    "text": "This project demonstrates how to create interactive plots in R using the plotly and ggiraph packages. The dataset comes from Kaggle, which reports the percentage of possible sunshine across major U.S. cities.\nThe goal was twofold:\n- Use plotly to create a line plot where users can isolate individual cities for closer inspection.\n- Use ggiraph to produce interactive bar charts that compare annual sunshine levels across cities.\n\n\n\nData preparation\n\nCleaned and reformatted city names.¬†\nConverted monthly sunshine percentages into long format for plotting.¬†\n\nInteractive line plot with plotly\n\nHighlighted cities of personal interest (Portland, Los Angeles, Honolulu, Chicago, Boston).¬†\nEnabled legend interactivity so double-clicking a city isolates its data.¬†\n\nInteractive bar charts with ggiraph\n\nBuilt grouped bar charts of annual sunshine by city.¬†\nAdded custom tooltips with CSS styling for clarity.\n\n\n\n\n\n\n\nLook at the code\n# load packages and read in data\nlibrary(tidyverse)\nlibrary(ggiraph)\nlibrary(plotly)\nlibrary(ggpubr)\nlibrary(patchwork)\n\nsunshine &lt;- readr::read_csv('./data/avg_sunshine.csv')\n\n# get cities into the right format\nsunshine$CITY &lt;- str_to_title(sunshine$CITY)\nsunshine$CITY &lt;- str_replace(sunshine$CITY, \",\", \", \")\nsunshine$CITY &lt;- gsub(\"(\\\\w$)\", \"\\\\U\\\\1\", sunshine$CITY, perl = TRUE)\n\n# get rid of duplicates\nsunshine &lt;- sunshine %&gt;% \n  filter(CITY != \"CitY\")\n\nsunshine &lt;- sunshine[!duplicated(sunshine$CITY), ]\n\n# get data into the right format\nsunshine &lt;- pivot_longer(sunshine, JAN:DEC, names_to = \"month\", values_to = \"temp\")\n\nsunshine &lt;- sunshine[, -4]\nsunshine$ANN&lt;-as.numeric(sunshine$ANN)\nsunshine$temp&lt;-as.numeric(sunshine$temp)\nsunshine$month&lt;-str_to_title(sunshine$month)\nsunshine$month&lt;-as.factor(sunshine$month)\nsunshine$perc_temp&lt;-sunshine$temp/100\n\n\nsun_cities &lt;- sunshine %&gt;% \n  filter(CITY %in% c(\"Portland, OR\", \"Los Angeles, CA\", \"Honolulu, HI\", \"Chicago, IL\", \"Boston, MA\"))\n\nsun_cities$month &lt;- factor(sun_cities$month, levels=c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"))\n\n\n\n# basic line plot for ggiraph\ngg_sunshine &lt;- sun_cities %&gt;%  \n  ggplot(aes(x = month, y=temp, text = paste0(\"Percent possible sunshine in\\n\",CITY, \": \", temp, \"% in \", month))) +\n  geom_line(aes(x = month, y = temp, color = CITY, group = CITY), alpha=0.8)+\n  labs(x=\"Month\", y=\"Average percent of possible sunshine\", color = \"City\", caption = \"Data from Kaggle.com: uploaded by user thedevastator\", title = \"How sunny are the cities that \\nare important to me?\", subtitle = \"Measured by time of sunshine reaching earth from sunrise to sunset\")+\n  theme_minimal()+\n  theme(\n        plot.title = element_text(vjust = 2),\n        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+\n  scale_y_continuous(labels = scales::percent_format(scale = 1))+\n  scale_color_manual(values=c(\"black\",\"#0454a4\", \"#5688c1\",\"#7ca4d4\", \"#b8cee6\"))\n\nggplotly(gg_sunshine, tooltip = 'text')\n\n\n\n\n\n\nLook at the code\n# working on the ggiraph\n\ntooltip_css &lt;- \"background-color:#7ca4d4;color:white;padding:5px;border-radius:3px;\"\n\navg_sun &lt;- sunshine %&gt;% group_by(CITY, ANN) %&gt;% summarize() %&gt;% na.omit()\n\n# Creating plots\navg_sun$tooltip &lt;- c(paste0(avg_sun$CITY,\": \", avg_sun$ANN, \"%\"))\n\nsun1 &lt;- avg_sun[1:38,] %&gt;% \n  ggplot()+\n  geom_col_interactive(aes(x=reorder(CITY, ANN), y=ANN/100,\n                           tooltip = tooltip,\n                      data_id = ANN), fill=\"#0454a4\")+\n  coord_flip()+\n    labs(x=\"\", y=\"Average annual sunshine\")+\n  theme_minimal()+\n  theme(axis.text.x = element_text(vjust = 2))+\n  lims(y=c(0,1))+\n  scale_y_continuous(labels = scales::percent)+\n  scale_x_discrete(labels=NULL)\n\n\nsun2&lt;-avg_sun[39:76,] %&gt;% \n  ggplot()+\n  geom_col_interactive(aes(x=reorder(CITY, ANN), y=ANN/100,\n                           tooltip = tooltip,\n                      data_id = ANN), fill=\"#0454a4\")+\n  coord_flip()+\n    labs(x=\"\", y=\"Average annual sunshine\")+\n  theme_minimal()+\n  theme(axis.text.x = element_text(vjust = 2))+\n  lims(y=c(0,1))+\n  scale_y_continuous(labels = scales::percent)+\n  scale_x_discrete(labels=NULL)\n\nsun3&lt;-avg_sun[77:115,] %&gt;% \n  ggplot()+\n  geom_col_interactive(aes(x=reorder(CITY, ANN), y=ANN/100,\n                           tooltip = tooltip,\n                      data_id = ANN), fill=\"#0454a4\")+\n  coord_flip()+\n    labs(x=\"\", y=\"Average annual sunshine\")+\n  theme_minimal()+\n  theme(axis.text.x = element_text(vjust = 2))+\n  lims(y=c(0,1))+\n  scale_y_continuous(labels = scales::percent)+\n  scale_x_discrete(labels=NULL)\n\nsun4&lt;-avg_sun[116:153,] %&gt;% \n  ggplot()+\n  geom_col_interactive(aes(x=reorder(CITY, ANN), y=ANN/100,\n                           tooltip = tooltip,\n                      data_id = ANN), fill=\"#0454a4\")+\n  coord_flip()+\n    labs(x=\"\", y=\"Average annual sunshine\")+\n  theme_minimal()+\n  theme(axis.text.x = element_text(vjust = 2))+\n  lims(y=c(0,1))+\n  scale_y_continuous(labels = scales::percent)+\n  scale_x_discrete(labels=NULL)\n\n p&lt;-ggarrange(sun1, sun2, sun3, sun4, ncol=2, nrow=2, labels=c(\"A\",\"B\",\"C\",\"D\"))\ngirafe(\n  code = print(p + plot_annotation(title=\"How sunny is your hometown?\", subtitle = \"Measured by time of sun shine reaching earth from sunrise to sunset\", caption = \"A: Abilene TX - Des Moines, IA\\nB: Detroit, MI - Las Vegas, NV\\nC: Lihue, HI - Providence, RI\\nD: Pueblo, CO - Yap- W Caroline Is., PC\\nData from Kaggle.com: uploaded by user thedevastator\", theme = theme(plot.caption.position = \"plot\", plot.caption = element_text(hjust = 0)))),\n  height_svg = 9,\n  width_svg = NULL,\n  options = list(\n    opts_tooltip(css = tooltip_css, opacity = 1),\n    opts_sizing(width = .7),\n    opts_hover(css = \"fill:#0454a4;stroke-width:2;\"),\n    opts_hover_inv(css = \"opacity:0.1;\"),\n    opts_selection(\n      type = \"single\", \n      only_shiny = FALSE,\n      css = \"fill:#0454a4\"),\n    opts_zoom(max=4)\n  )\n)\n\n\n\n\n\n\n\n\n\nThe interactive visualizations make it easy to explore both seasonal and geographic variation in sunshine. With plotly, users can highlight specific cities by double-clicking the city in the legend and compare seasonal changes. With ggiraph, tooltips and hover effects provide immediate context for annual averages across more than 150 cities.\nOne interesting finding is Los Angeles‚Äôs dip in May‚ÄìJune sunshine compared to adjacent months, a feature that might reflect local climate effects (e.g., ‚ÄúJune Gloom‚Äù).\n\n\n\n\n\n\nHow do I make a plot interactive with plotly?\n\n\nWrap a ggplot object in ggplotly() or build directly with plot_ly(). Interactivity (zoom, pan, legend toggling) is handled automatically.\n\n\n\n\nHow do I add tooltips in ggiraph?\n\n\nUse geom_col_interactive() or geom_point_interactive() with a tooltip aesthetic. Custom styling can be passed through opts_tooltip().\n\n\n\n\nCan I combine multiple ggiraph plots?\n\n\nYes. Arrange them with packages like patchwork or ggpubr, then pass the combined object into girafe().\n\n\n\n\nWhat file formats can I export to?\n\n\nBoth packages support exporting to HTML. ggiraph visualizations can also be integrated into Shiny apps, R Markdown, and Quarto documents."
  },
  {
    "objectID": "posts/interactive-visualization-r-plotly-ggiraph.html#example-code",
    "href": "posts/interactive-visualization-r-plotly-ggiraph.html#example-code",
    "title": "Interactive Data Visualization in R with plotly and ggiraph",
    "section": "Example Code",
    "text": "Example Code\n\n\nLook at the code\n# load packages and read in data\nlibrary(tidyverse)\nlibrary(ggiraph)\nlibrary(plotly)\nlibrary(ggpubr)\nlibrary(patchwork)\n\nsunshine &lt;- readr::read_csv('./data/avg_sunshine.csv')\n\n# get cities into the right format\nsunshine$CITY &lt;- str_to_title(sunshine$CITY)\nsunshine$CITY &lt;- str_replace(sunshine$CITY, \",\", \", \")\nsunshine$CITY &lt;- gsub(\"(\\\\w$)\", \"\\\\U\\\\1\", sunshine$CITY, perl = TRUE)\n\n# get rid of duplicates\nsunshine &lt;- sunshine %&gt;% \n  filter(CITY != \"CitY\")\n\nsunshine &lt;- sunshine[!duplicated(sunshine$CITY), ]\n\n# get data into the right format\nsunshine &lt;- pivot_longer(sunshine, JAN:DEC, names_to = \"month\", values_to = \"temp\")\n\nsunshine &lt;- sunshine[, -4]\nsunshine$ANN&lt;-as.numeric(sunshine$ANN)\nsunshine$temp&lt;-as.numeric(sunshine$temp)\nsunshine$month&lt;-str_to_title(sunshine$month)\nsunshine$month&lt;-as.factor(sunshine$month)\nsunshine$perc_temp&lt;-sunshine$temp/100\n\n\nsun_cities &lt;- sunshine %&gt;% \n  filter(CITY %in% c(\"Portland, OR\", \"Los Angeles, CA\", \"Honolulu, HI\", \"Chicago, IL\", \"Boston, MA\"))\n\nsun_cities$month &lt;- factor(sun_cities$month, levels=c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"))\n\n\n\n# basic line plot for ggiraph\ngg_sunshine &lt;- sun_cities %&gt;%  \n  ggplot(aes(x = month, y=temp, text = paste0(\"Percent possible sunshine in\\n\",CITY, \": \", temp, \"% in \", month))) +\n  geom_line(aes(x = month, y = temp, color = CITY, group = CITY), alpha=0.8)+\n  labs(x=\"Month\", y=\"Average percent of possible sunshine\", color = \"City\", caption = \"Data from Kaggle.com: uploaded by user thedevastator\", title = \"How sunny are the cities that \\nare important to me?\", subtitle = \"Measured by time of sunshine reaching earth from sunrise to sunset\")+\n  theme_minimal()+\n  theme(\n        plot.title = element_text(vjust = 2),\n        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+\n  scale_y_continuous(labels = scales::percent_format(scale = 1))+\n  scale_color_manual(values=c(\"black\",\"#0454a4\", \"#5688c1\",\"#7ca4d4\", \"#b8cee6\"))\n\nggplotly(gg_sunshine, tooltip = 'text')\n\n\n\n\n\n\nLook at the code\n# working on the ggiraph\n\ntooltip_css &lt;- \"background-color:#7ca4d4;color:white;padding:5px;border-radius:3px;\"\n\navg_sun &lt;- sunshine %&gt;% group_by(CITY, ANN) %&gt;% summarize() %&gt;% na.omit()\n\n# Creating plots\navg_sun$tooltip &lt;- c(paste0(avg_sun$CITY,\": \", avg_sun$ANN, \"%\"))\n\nsun1 &lt;- avg_sun[1:38,] %&gt;% \n  ggplot()+\n  geom_col_interactive(aes(x=reorder(CITY, ANN), y=ANN/100,\n                           tooltip = tooltip,\n                      data_id = ANN), fill=\"#0454a4\")+\n  coord_flip()+\n    labs(x=\"\", y=\"Average annual sunshine\")+\n  theme_minimal()+\n  theme(axis.text.x = element_text(vjust = 2))+\n  lims(y=c(0,1))+\n  scale_y_continuous(labels = scales::percent)+\n  scale_x_discrete(labels=NULL)\n\n\nsun2&lt;-avg_sun[39:76,] %&gt;% \n  ggplot()+\n  geom_col_interactive(aes(x=reorder(CITY, ANN), y=ANN/100,\n                           tooltip = tooltip,\n                      data_id = ANN), fill=\"#0454a4\")+\n  coord_flip()+\n    labs(x=\"\", y=\"Average annual sunshine\")+\n  theme_minimal()+\n  theme(axis.text.x = element_text(vjust = 2))+\n  lims(y=c(0,1))+\n  scale_y_continuous(labels = scales::percent)+\n  scale_x_discrete(labels=NULL)\n\nsun3&lt;-avg_sun[77:115,] %&gt;% \n  ggplot()+\n  geom_col_interactive(aes(x=reorder(CITY, ANN), y=ANN/100,\n                           tooltip = tooltip,\n                      data_id = ANN), fill=\"#0454a4\")+\n  coord_flip()+\n    labs(x=\"\", y=\"Average annual sunshine\")+\n  theme_minimal()+\n  theme(axis.text.x = element_text(vjust = 2))+\n  lims(y=c(0,1))+\n  scale_y_continuous(labels = scales::percent)+\n  scale_x_discrete(labels=NULL)\n\nsun4&lt;-avg_sun[116:153,] %&gt;% \n  ggplot()+\n  geom_col_interactive(aes(x=reorder(CITY, ANN), y=ANN/100,\n                           tooltip = tooltip,\n                      data_id = ANN), fill=\"#0454a4\")+\n  coord_flip()+\n    labs(x=\"\", y=\"Average annual sunshine\")+\n  theme_minimal()+\n  theme(axis.text.x = element_text(vjust = 2))+\n  lims(y=c(0,1))+\n  scale_y_continuous(labels = scales::percent)+\n  scale_x_discrete(labels=NULL)\n\n p&lt;-ggarrange(sun1, sun2, sun3, sun4, ncol=2, nrow=2, labels=c(\"A\",\"B\",\"C\",\"D\"))\ngirafe(\n  code = print(p + plot_annotation(title=\"How sunny is your hometown?\", subtitle = \"Measured by time of sun shine reaching earth from sunrise to sunset\", caption = \"A: Abilene TX - Des Moines, IA\\nB: Detroit, MI - Las Vegas, NV\\nC: Lihue, HI - Providence, RI\\nD: Pueblo, CO - Yap- W Caroline Is., PC\\nData from Kaggle.com: uploaded by user thedevastator\", theme = theme(plot.caption.position = \"plot\", plot.caption = element_text(hjust = 0)))),\n  height_svg = 9,\n  width_svg = NULL,\n  options = list(\n    opts_tooltip(css = tooltip_css, opacity = 1),\n    opts_sizing(width = .7),\n    opts_hover(css = \"fill:#0454a4;stroke-width:2;\"),\n    opts_hover_inv(css = \"opacity:0.1;\"),\n    opts_selection(\n      type = \"single\", \n      only_shiny = FALSE,\n      css = \"fill:#0454a4\"),\n    opts_zoom(max=4)\n  )\n)"
  },
  {
    "objectID": "posts/interactive-visualization-r-plotly-ggiraph.html#workflow",
    "href": "posts/interactive-visualization-r-plotly-ggiraph.html#workflow",
    "title": "Interactive Data Visualization in R with plotly and ggiraph",
    "section": "Workflow",
    "text": "Workflow\n\nData preparation\n\nCleaned and reformatted city names.\n\nConverted monthly sunshine percentages into long format for plotting.\n\n\nInteractive line plot with plotly\n\nHighlighted cities of personal interest (Portland, Los Angeles, Honolulu, Chicago, Boston).\n\nEnabled legend interactivity so double-clicking a city isolates its data.\n\n\nInteractive bar charts with ggiraph\n\nBuilt grouped bar charts of annual sunshine by city.\n\nAdded custom tooltips with CSS styling for clarity."
  },
  {
    "objectID": "posts/interactive-visualization-r-plotly-ggiraph.html#results",
    "href": "posts/interactive-visualization-r-plotly-ggiraph.html#results",
    "title": "Interactive Data Visualization in R with plotly and ggiraph",
    "section": "Results",
    "text": "Results\nThe interactive visualizations make it easy to explore both seasonal and geographic variation in sunshine. With plotly, users can highlight specific cities and compare seasonal changes. With ggiraph, tooltips and hover effects provide immediate context for annual averages across more than 150 cities.\nOne interesting finding is Los Angeles‚Äôs dip in May‚ÄìJune sunshine compared to adjacent months, a feature that might reflect local climate effects (e.g., ‚ÄúJune Gloom‚Äù)."
  },
  {
    "objectID": "posts/interactive-visualization-r-plotly-ggiraph.html#faq-working-with-ggiraph-and-plotly-in-r",
    "href": "posts/interactive-visualization-r-plotly-ggiraph.html#faq-working-with-ggiraph-and-plotly-in-r",
    "title": "Interactive Data Visualization in R with plotly and ggiraph",
    "section": "FAQ: Working with ggiraph and plotly in R",
    "text": "FAQ: Working with ggiraph and plotly in R\n\n\n\nHow do I make a plot interactive with plotly?\n\n\nWrap a ggplot object in ggplotly() or build directly with plot_ly(). Interactivity (zoom, pan, legend toggling) is handled automatically.\n\n\n\n\nHow do I add tooltips in ggiraph?\n\n\nUse geom_col_interactive() or geom_point_interactive() with a tooltip aesthetic. Custom styling can be passed through opts_tooltip().\n\n\n\n\nCan I combine multiple ggiraph plots?\n\n\nYes. Arrange them with packages like patchwork or ggpubr, then pass the combined object into girafe().\n\n\n\n\nWhat file formats can I export to?\n\n\nBoth packages support exporting to HTML. ggiraph visualizations can also be integrated into Shiny apps, R Markdown, and Quarto documents."
  },
  {
    "objectID": "posts/super-bowl-champions-r-gt-table.html#workflow",
    "href": "posts/super-bowl-champions-r-gt-table.html#workflow",
    "title": "Super Bowl Champions: Analysis Using the gt R Package",
    "section": "Workflow",
    "text": "Workflow\n\nLoad and prepare the data\n\nImported a Super Bowl dataset (winners, losers, scores, dates, host cities).\n\nAdded a column of team logo URLs.\n\nApplied as.Date() and conditional year formatting to create a consistent date format.\n\n\nFormat with gt\n\nHighlighted the game number, date, teams, scores, and location.\n\nUsed text_transform() and web_image() to render team logos.\n\nCreated aesthetic labels and spanners for winning and losing teams.\n\nApplied fmt_date() for aesthetic date formatting.\n\n\nExport the final table\n\nSaved the result as PNG for social preview image."
  },
  {
    "objectID": "posts/super-bowl-champions-r-gt-table.html#code-results",
    "href": "posts/super-bowl-champions-r-gt-table.html#code-results",
    "title": "Super Bowl Champions: Analysis Using the gt R Package",
    "section": "Code & Results",
    "text": "Code & Results\n\n\nLook at the code\n# load packages and read in data\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(lubridate)\n\nsuperbowls &lt;- readr::read_csv('./data/Super_Bowl.csv')\n \n# add logos for each team\nsuperbowls &lt;- superbowls %&gt;% \n  mutate(win_logo_url = \n  case_when(\n          Winner == \"Green Bay Packers\" ~ \"https://upload.wikimedia.org/wikipedia/commons/5/50/Green_Bay_Packers_logo.svg\",\n          Winner == \"New York Jets\" ~ \"https://upload.wikimedia.org/wikipedia/en/6/6b/New_York_Jets_logo.svg\",\n          Winner == \"Kansas City Chiefs\" ~ \"https://upload.wikimedia.org/wikipedia/en/e/e1/Kansas_City_Chiefs_logo.svg\",\n          Winner == \"Baltimore Colts\" ~ \"https://upload.wikimedia.org/wikipedia/en/1/1f/Baltimore_Colts_logo_1961-1978.gif\",\n          Winner == \"Dallas Cowboys\" ~ \"https://upload.wikimedia.org/wikipedia/commons/1/15/Dallas_Cowboys.svg\",\n          Winner == \"Miami Dolphins\" ~ \"https://upload.wikimedia.org/wikipedia/en/3/37/Miami_Dolphins_logo.svg\",\n          Winner == \"Pittsburgh Steelers\" ~ \"https://upload.wikimedia.org/wikipedia/commons/d/de/Pittsburgh_Steelers_logo.svg\",\n          Winner == \"Oakland Raiders\" ~ \"https://upload.wikimedia.org/wikipedia/en/4/48/Las_Vegas_Raiders_logo.svg\",\n          Winner == \"Los Angeles Raiders\" ~ \"https://upload.wikimedia.org/wikipedia/en/4/48/Las_Vegas_Raiders_logo.svg\",\n          Winner == \"San Francisco 49ers\" ~ \"https://upload.wikimedia.org/wikipedia/commons/3/3a/San_Francisco_49ers_logo.svg\",\n          Winner == \"Washington Redskins\" ~ \"https://e7.pngegg.com/pngimages/193/260/png-clipart-redskins-logo-red-skins-logo-sports-nfl-football.png\",\n          Winner == \"Chicago Bears\" ~ \"https://upload.wikimedia.org/wikipedia/commons/5/5c/Chicago_Bears_logo.svg\",\n          Winner == \"New York Giants\" ~ \"https://upload.wikimedia.org/wikipedia/commons/6/60/New_York_Giants_logo.svg\",\n          Winner == \"Denver Broncos\" ~ \"https://upload.wikimedia.org/wikipedia/en/4/44/Denver_Broncos_logo.svg\",\n          Winner == \"St. Louis Rams\" ~ \"https://upload.wikimedia.org/wikipedia/en/8/8b/NFL_Rams_logo.svg\",\n          Winner == \"Baltimore Ravens\" ~ \"https://upload.wikimedia.org/wikipedia/en/1/16/Baltimore_Ravens_logo.svg\",\n          Winner == \"New England Patriots\" ~ \"https://upload.wikimedia.org/wikipedia/en/b/b9/New_England_Patriots_logo.svg\",\n          Winner == \"Tampa Bay Buccaneers\" ~ \"https://upload.wikimedia.org/wikipedia/en/a/a2/Tampa_Bay_Buccaneers_logo.svg\",\n          Winner == \"Indianapolis Colts\" ~ \"https://upload.wikimedia.org/wikipedia/commons/0/00/Indianapolis_Colts_logo.svg\",\n          Winner == \"New Orleans Saints\" ~ \"https://upload.wikimedia.org/wikipedia/commons/5/50/New_Orleans_Saints_logo.svg\",\n          Winner == \"Seattle Seahawks\" ~ \"https://upload.wikimedia.org/wikipedia/en/8/8e/Seattle_Seahawks_logo.svg\",\n          Winner == \"Philadelphia Eagles\" ~ \"https://upload.wikimedia.org/wikipedia/en/8/8e/Philadelphia_Eagles_logo.svg\"\n          )\n       ) %&gt;% \n  mutate(lose_logo_url = \n  case_when(\n          Loser == \"Green Bay Packers\" ~ \"https://upload.wikimedia.org/wikipedia/commons/5/50/Green_Bay_Packers_logo.svg\",\n            Loser == \"Minnesota Vikings\" ~ \"https://upload.wikimedia.org/wikipedia/en/4/48/Minnesota_Vikings_logo.svg\",\n          Loser == \"Kansas City Chiefs\" ~ \"https://upload.wikimedia.org/wikipedia/en/e/e1/Kansas_City_Chiefs_logo.svg\",\n          Loser == \"Baltimore Colts\" ~ \"https://upload.wikimedia.org/wikipedia/en/1/1f/Baltimore_Colts_logo_1961-1978.gif\",\n          Loser == \"Dallas Cowboys\" ~ \"https://upload.wikimedia.org/wikipedia/commons/1/15/Dallas_Cowboys.svg\",\n          Loser == \"Miami Dolphins\" ~ \"https://upload.wikimedia.org/wikipedia/en/3/37/Miami_Dolphins_logo.svg\",\n          Loser == \"Pittsburgh Steelers\" ~ \"https://upload.wikimedia.org/wikipedia/commons/d/de/Pittsburgh_Steelers_logo.svg\",\n          Loser == \"Oakland Raiders\" ~ \"https://upload.wikimedia.org/wikipedia/en/4/48/Las_Vegas_Raiders_logo.svg\",\n          Loser == \"Los Angeles Rams\" ~ \"https://upload.wikimedia.org/wikipedia/en/8/8a/Los_Angeles_Rams_logo.svg\",\n          Loser == \"San Francisco 49ers\" ~ \"https://upload.wikimedia.org/wikipedia/commons/3/3a/San_Francisco_49ers_logo.svg\",\n          Loser == \"Washington Redskins\" ~ \"https://e7.pngegg.com/pngimages/193/260/png-clipart-redskins-logo-red-skins-logo-sports-nfl-football.png\",\n          Loser == \"Chicago Bears\" ~ \"https://upload.wikimedia.org/wikipedia/commons/5/5c/Chicago_Bears_logo.svg\",\n          Loser == \"New York Giants\" ~ \"https://upload.wikimedia.org/wikipedia/commons/6/60/New_York_Giants_logo.svg\",\n          Loser == \"Denver Broncos\" ~ \"https://upload.wikimedia.org/wikipedia/en/4/44/Denver_Broncos_logo.svg\",\n          Loser == \"St. Louis Rams\" ~ \"https://upload.wikimedia.org/wikipedia/en/8/8b/NFL_Rams_logo.svg\",\n           Loser == \"Cincinnati Bengals\" ~ \"https://upload.wikimedia.org/wikipedia/commons/8/81/Cincinnati_Bengals_logo.svg\",\n          Loser == \"New England Patriots\" ~ \"https://upload.wikimedia.org/wikipedia/en/b/b9/New_England_Patriots_logo.svg\",\n           Loser == \"Buffalo Bills\" ~ \"https://upload.wikimedia.org/wikipedia/en/7/77/Buffalo_Bills_logo.svg\",\n          Loser == \"Indianapolis Colts\" ~ \"https://upload.wikimedia.org/wikipedia/commons/0/00/Indianapolis_Colts_logo.svg\",\n           Loser == \"San Diego Chargers\" ~ \"https://upload.wikimedia.org/wikipedia/en/7/72/NFL_Chargers_logo.svg\",\n          Loser == \"Seattle Seahawks\" ~ \"https://upload.wikimedia.org/wikipedia/en/8/8e/Seattle_Seahawks_logo.svg\",\n          Loser == \"Philadelphia Eagles\" ~ \"https://upload.wikimedia.org/wikipedia/en/8/8e/Philadelphia_Eagles_logo.svg\",\n          Loser == \"Atlanta Falcons\" ~ \"https://upload.wikimedia.org/wikipedia/en/c/c5/Atlanta_Falcons_logo.svg\",\n          Loser == \"Tennessee Titans\" ~ \"https://upload.wikimedia.org/wikipedia/en/c/c1/Tennessee_Titans_logo.svg\",\n          Loser == \"Carolina Panthers\" ~ \"https://upload.wikimedia.org/wikipedia/en/1/1c/Carolina_Panthers_logo.svg\",\n          Loser == \"Arizona Cardinals\" ~ \"https://upload.wikimedia.org/wikipedia/en/7/72/Arizona_Cardinals_logo.svg\"\n          )\n       )\n\n# Choosing a subset of columns to display basic information about the Super Bowl\nsuperbowls&lt;-superbowls %&gt;% \n  dplyr::select(\"SB\", \"Date\", \"win_logo_url\", \"Winner\", \"Winning Pts\", \"lose_logo_url\", \"Loser\", \"Losing Pts\", \"City\", \"State\")\n\n# convert to date format\nsuperbowls$Date &lt;- as.Date(superbowls$Date, '%d-%b-%Y') %m+% years(2000) \n# convert to 4 digit year format\nsuperbowls$Date &lt;- dplyr::if_else(superbowls$Date &gt; '2023-01-01', superbowls$Date %m-% years(100), superbowls$Date)\n\n\n# create gt table  \nsuperbowls %&gt;% \n  gt() %&gt;% \n  # add title and subtitle\n  tab_header(\n    title = md(\"**Super Bowl Winners**\"),\n    subtitle = \"Super Bowl I-LII\"\n  ) %&gt;%\n  # format date\n  fmt_date(\n    columns = Date,\n    date_style = 5\n  ) %&gt;%\n  # add winning team label\n  tab_spanner(\n    label = md(\"**Winning Team**\"),\n    columns = c(win_logo_url, Winner, `Winning Pts`)\n  ) %&gt;% \n  # add losing team label\n  tab_spanner(\n    label = \"Losing Team\",\n    columns = c(lose_logo_url, Loser, `Losing Pts`)\n  ) %&gt;% \n  # add location label\n  tab_spanner(\n    label = \"Location\",\n    columns = c(City, State)\n  ) %&gt;% \n  # add super bowl label\n  tab_spanner(\n    label = \"Super Bowl\",\n    columns = c(SB, Date)\n  ) %&gt;% \n  # align the text to center\n  cols_align(\n    align = \"center\") %&gt;% \n  # change names of columns\n  cols_label(\n    SB = \"Number\",\n    Winner = md(\"**Name**\"),\n    `Winning Pts` = md(\"**Points**\"),\n    Loser = \"Name\",\n    `Losing Pts` = \"Points\"\n  ) %&gt;%\n  # convert urls to images\n  text_transform(\n    #Apply a function to a column\n    locations = cells_body(c(win_logo_url, lose_logo_url)),\n    fn = function(x) {\n      #Return an image of set dimensions\n      web_image(\n        url = x,\n        height = 15\n      )\n    }\n  ) %&gt;%\n  #Hide column headers and reduce width\n  cols_width(c(win_logo_url, lose_logo_url) ~ px(30)) %&gt;% \n  cols_label(win_logo_url = \"\") %&gt;% \n  cols_label(lose_logo_url = \"\") %&gt;%\n  # change colors of winning and losing teams\n  tab_style(\n    style = list(\n      cell_fill(\"darkseagreen1\"),\n      cell_text(weight = \"bold\")\n    ),\n    locations = cells_body(\n      columns = c(win_logo_url, Winner, `Winning Pts`)\n    )\n  ) %&gt;% \n  tab_style(\n    style = list(\n      cell_fill(\"#FFADAD\")\n    ),\n    locations = cells_body(\n      columns = c(lose_logo_url, Loser, `Losing Pts`)\n    )\n  ) %&gt;% \n  # add reference footnote\n  tab_source_note(\n    source_note = html(\"Source: &lt;b&gt;Super Bowl Results, Officials, and MVPs&lt;/b&gt;, dataset uploaded by user thedevastator to &lt;a href ='https://www.kaggle.com/datasets/thedevastator/super-bowl-results-officials-and-mvps-1967-2020'&gt;Kaggle.com&lt;/a&gt;.\")\n  )\n\n\n\n\n\n\n\n\nSuper Bowl Winners\n\n\nSuper Bowl I-LII\n\n\n\nSuper Bowl\n\n\nWinning Team\n\n\nLosing Team\n\n\nLocation\n\n\n\nNumber\nDate\n\nName\nPoints\n\nName\nPoints\nCity\nState\n\n\n\n\nI\nJanuary 15, 1967\n\nGreen Bay Packers\n35\n\nKansas City Chiefs\n10\nLos Angeles\nCalifornia\n\n\nII\nJanuary 14, 1968\n\nGreen Bay Packers\n33\n\nOakland Raiders\n14\nMiami\nFlorida\n\n\nIII\nJanuary 12, 1969\n\nNew York Jets\n16\n\nBaltimore Colts\n7\nMiami\nFlorida\n\n\nIV\nJanuary 11, 1970\n\nKansas City Chiefs\n23\n\nMinnesota Vikings\n7\nNew Orleans\nLouisiana\n\n\nV\nJanuary 17, 1971\n\nBaltimore Colts\n16\n\nDallas Cowboys\n13\nMiami\nFlorida\n\n\nVI\nJanuary 16, 1972\n\nDallas Cowboys\n24\n\nMiami Dolphins\n3\nNew Orleans\nLouisiana\n\n\nVII\nJanuary 14, 1973\n\nMiami Dolphins\n14\n\nWashington Redskins\n7\nLos Angeles\nCalifornia\n\n\nVIII\nJanuary 13, 1974\n\nMiami Dolphins\n24\n\nMinnesota Vikings\n7\nHouston\nTexas\n\n\nIX\nJanuary 12, 1975\n\nPittsburgh Steelers\n16\n\nMinnesota Vikings\n6\nNew Orleans\nLouisiana\n\n\nX\nJanuary 18, 1976\n\nPittsburgh Steelers\n21\n\nDallas Cowboys\n17\nMiami\nFlorida\n\n\nXI\nJanuary 9, 1977\n\nOakland Raiders\n32\n\nMinnesota Vikings\n14\nPasadena\nCalifornia\n\n\nXII\nJanuary 15, 1978\n\nDallas Cowboys\n27\n\nDenver Broncos\n10\nNew Orleans\nLouisiana\n\n\nXIII\nJanuary 21, 1979\n\nPittsburgh Steelers\n35\n\nDallas Cowboys\n31\nMiami\nFlorida\n\n\nXIV\nJanuary 20, 1980\n\nPittsburgh Steelers\n31\n\nLos Angeles Rams\n19\nPasadena\nCalifornia\n\n\nXV\nJanuary 25, 1981\n\nOakland Raiders\n27\n\nPhiladelphia Eagles\n10\nNew Orleans\nLouisiana\n\n\nXVI\nJanuary 24, 1982\n\nSan Francisco 49ers\n26\n\nCincinnati Bengals\n21\nPontiac\nMichigan\n\n\nXVII\nJanuary 30, 1983\n\nWashington Redskins\n27\n\nMiami Dolphins\n17\nPasadena\nCalifornia\n\n\nXVIII\nJanuary 22, 1984\n\nLos Angeles Raiders\n38\n\nWashington Redskins\n9\nTampa\nFlorida\n\n\nXIX\nJanuary 20, 1985\n\nSan Francisco 49ers\n38\n\nMiami Dolphins\n16\nPalo Alto\nCalifornia\n\n\nXX\nJanuary 26, 1986\n\nChicago Bears\n46\n\nNew England Patriots\n10\nNew Orleans\nLouisiana\n\n\nXXI\nJanuary 25, 1987\n\nNew York Giants\n39\n\nDenver Broncos\n20\nPasadena\nCalifornia\n\n\nXXII\nJanuary 31, 1988\n\nWashington Redskins\n42\n\nDenver Broncos\n10\nSan Diego\nCalifornia\n\n\nXXIII\nJanuary 22, 1989\n\nSan Francisco 49ers\n20\n\nCincinnati Bengals\n16\nMiami Gardens\nFlorida\n\n\nXXIV\nJanuary 28, 1990\n\nSan Francisco 49ers\n55\n\nDenver Broncos\n10\nNew Orleans\nLouisiana\n\n\nXXV\nJanuary 27, 1991\n\nNew York Giants\n20\n\nBuffalo Bills\n19\nTampa\nFlorida\n\n\nXXVI\nJanuary 26, 1992\n\nWashington Redskins\n37\n\nBuffalo Bills\n24\nMinneapolis\nMinnesota\n\n\nXXVII\nJanuary 31, 1993\n\nDallas Cowboys\n52\n\nBuffalo Bills\n17\nPasadena\nCalifornia\n\n\nXXVIII\nJanuary 30, 1994\n\nDallas Cowboys\n30\n\nBuffalo Bills\n13\nAtlanta\nGeorgia\n\n\nXXIX\nJanuary 29, 1995\n\nSan Francisco 49ers\n49\n\nSan Diego Chargers\n26\nMiami Gardens\nFlorida\n\n\nXXX\nJanuary 28, 1996\n\nDallas Cowboys\n27\n\nPittsburgh Steelers\n17\nTempe\nArizona\n\n\nXXXI\nJanuary 26, 1997\n\nGreen Bay Packers\n35\n\nNew England Patriots\n21\nNew Orleans\nLouisiana\n\n\nXXXII\nJanuary 25, 1998\n\nDenver Broncos\n31\n\nGreen Bay Packers\n24\nSan Diego\nCalifornia\n\n\nXXXIII\nJanuary 31, 1999\n\nDenver Broncos\n34\n\nAtlanta Falcons\n19\nMiami Gardens\nFlorida\n\n\nXXXIV\nJanuary 30, 2000\n\nSt. Louis Rams\n23\n\nTennessee Titans\n16\nAtlanta\nGeorgia\n\n\nXXXV\nJanuary 28, 2001\n\nBaltimore Ravens\n34\n\nNew York Giants\n7\nTampa\nFlorida\n\n\nXXXVI\nFebruary 3, 2002\n\nNew England Patriots\n20\n\nSt. Louis Rams\n17\nNew Orleans\nLouisiana\n\n\nXXXVII\nJanuary 26, 2003\n\nTampa Bay Buccaneers\n48\n\nOakland Raiders\n21\nSan Diego\nCalifornia\n\n\nXXXVIII\nFebruary 1, 2004\n\nNew England Patriots\n32\n\nCarolina Panthers\n29\nHouston\nTexas\n\n\nXXXIX\nFebruary 6, 2005\n\nNew England Patriots\n24\n\nPhiladelphia Eagles\n21\nJacksonville\nFlorida\n\n\nXL\nFebruary 5, 2006\n\nPittsburgh Steelers\n21\n\nSeattle Seahawks\n10\nDetroit\nMichigan\n\n\nXLI\nFebruary 4, 2007\n\nIndianapolis Colts\n29\n\nChicago Bears\n17\nMiami Gardens\nFlorida\n\n\nXLII\nFebruary 3, 2008\n\nNew York Giants\n17\n\nNew England Patriots\n14\nGlendale\nArizona\n\n\nXLIII\nFebruary 1, 2009\n\nPittsburgh Steelers\n27\n\nArizona Cardinals\n23\nTampa\nFlorida\n\n\nXLIV\nFebruary 7, 2010\n\nNew Orleans Saints\n31\n\nIndianapolis Colts\n17\nMiami Gardens\nFlorida\n\n\nXLV\nFebruary 6, 2011\n\nGreen Bay Packers\n31\n\nPittsburgh Steelers\n25\nArlington\nTexas\n\n\nXLVI\nFebruary 5, 2012\n\nNew York Giants\n21\n\nNew England Patriots\n17\nIndianapolis\nIndiana\n\n\nXLVII\nFebruary 3, 2013\n\nBaltimore Ravens\n34\n\nSan Francisco 49ers\n31\nNew Orleans\nLouisiana\n\n\nXLVIII\nFebruary 2, 2014\n\nSeattle Seahawks\n43\n\nDenver Broncos\n8\nEast Rutherford\nNew Jersey\n\n\nXLIX\nFebruary 1, 2015\n\nNew England Patriots\n28\n\nSeattle Seahawks\n24\nGlendale\nArizona\n\n\nL\nFebruary 7, 2016\n\nDenver Broncos\n24\n\nCarolina Panthers\n10\nSanta Clara\nCalifornia\n\n\nLI\nFebruary 5, 2017\n\nNew England Patriots\n34\n\nAtlanta Falcons\n28\nHouston\nTexas\n\n\nLII\nFebruary 4, 2018\n\nPhiladelphia Eagles\n41\n\nNew England Patriots\n33\nMinneapolis\nMinnesota\n\n\n\nSource: Super Bowl Results, Officials, and MVPs, dataset uploaded by user thedevastator to Kaggle.com."
  },
  {
    "objectID": "posts/super-bowl-champions-r-gt-table.html#discussion",
    "href": "posts/super-bowl-champions-r-gt-table.html#discussion",
    "title": "Super Bowl Champions: Analysis Using the gt R Package",
    "section": "Discussion",
    "text": "Discussion\nThe finished table shows every champion (as of 2023) since the first Super Bowl, along with team logos, scores, and host cities. It provides a quick way to explore the history of the event while highlighting the flexibility of gt.\nAs a Bengals fan, I noticed they‚Äôre still waiting for their first title üòÖ. That aside, the table offers a comprehensive view of the NFL‚Äôs biggest stage and is an example of how gt can be used to create effective visualizations in sports analytics projects."
  },
  {
    "objectID": "posts/super-bowl-champions-r-gt-table.html#faq-working-with-gt-in-r",
    "href": "posts/super-bowl-champions-r-gt-table.html#faq-working-with-gt-in-r",
    "title": "Super Bowl Champions: Analysis Using the gt R Package",
    "section": "FAQ: Working with gt in R",
    "text": "FAQ: Working with gt in R\n\n\n\nHow do I add images or team logos to a gt table in R?\n\n\nUse text_transform() with web_image() or local_image() to replace text with logos in your table.\n\n\n\n\nHow can I format dates and scores in gt?\n\n\nFunctions like fmt_date() and fmt_number() control display formats while keeping raw data intact.\n\n\n\n\nCan I export a gt table to share outside of R?\n\n\nYes. Use gtsave() to export to HTML, PNG, or PDF.\n\n\n\n\nIs gt only for sports data?\n\n\nNo.¬†gt works well for any structured dataset‚Äîfinance, education, scientific research, and more."
  },
  {
    "objectID": "posts/interactive-visualization-r-plotly-ggiraph.html#code-results",
    "href": "posts/interactive-visualization-r-plotly-ggiraph.html#code-results",
    "title": "Interactive Data Visualization in R with plotly and ggiraph",
    "section": "Code & Results",
    "text": "Code & Results\n\n\nLook at the code\n# load packages and read in data\nlibrary(tidyverse)\nlibrary(ggiraph)\nlibrary(plotly)\nlibrary(ggpubr)\nlibrary(patchwork)\n\nsunshine &lt;- readr::read_csv('./data/avg_sunshine.csv')\n\n# get cities into the right format\nsunshine$CITY &lt;- str_to_title(sunshine$CITY)\nsunshine$CITY &lt;- str_replace(sunshine$CITY, \",\", \", \")\nsunshine$CITY &lt;- gsub(\"(\\\\w$)\", \"\\\\U\\\\1\", sunshine$CITY, perl = TRUE)\n\n# get rid of duplicates\nsunshine &lt;- sunshine %&gt;% \n  filter(CITY != \"CitY\")\n\nsunshine &lt;- sunshine[!duplicated(sunshine$CITY), ]\n\n# get data into the right format\nsunshine &lt;- pivot_longer(sunshine, JAN:DEC, names_to = \"month\", values_to = \"temp\")\n\nsunshine &lt;- sunshine[, -4]\nsunshine$ANN&lt;-as.numeric(sunshine$ANN)\nsunshine$temp&lt;-as.numeric(sunshine$temp)\nsunshine$month&lt;-str_to_title(sunshine$month)\nsunshine$month&lt;-as.factor(sunshine$month)\nsunshine$perc_temp&lt;-sunshine$temp/100\n\n\nsun_cities &lt;- sunshine %&gt;% \n  filter(CITY %in% c(\"Portland, OR\", \"Los Angeles, CA\", \"Honolulu, HI\", \"Chicago, IL\", \"Boston, MA\"))\n\nsun_cities$month &lt;- factor(sun_cities$month, levels=c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"))\n\n\n\n# basic line plot for ggiraph\ngg_sunshine &lt;- sun_cities %&gt;%  \n  ggplot(aes(x = month, y=temp, text = paste0(\"Percent possible sunshine in\\n\",CITY, \": \", temp, \"% in \", month))) +\n  geom_line(aes(x = month, y = temp, color = CITY, group = CITY), alpha=0.8)+\n  labs(x=\"Month\", y=\"Average percent of possible sunshine\", color = \"City\", caption = \"Data from Kaggle.com: uploaded by user thedevastator\", title = \"How sunny are the cities that \\nare important to me?\", subtitle = \"Measured by time of sunshine reaching earth from sunrise to sunset\")+\n  theme_minimal()+\n  theme(\n        plot.title = element_text(vjust = 2),\n        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+\n  scale_y_continuous(labels = scales::percent_format(scale = 1))+\n  scale_color_manual(values=c(\"black\",\"#0454a4\", \"#5688c1\",\"#7ca4d4\", \"#b8cee6\"))\n\nggplotly(gg_sunshine, tooltip = 'text')\n\n\n\n\n\n\nLook at the code\n# working on the ggiraph\n\ntooltip_css &lt;- \"background-color:#7ca4d4;color:white;padding:5px;border-radius:3px;\"\n\navg_sun &lt;- sunshine %&gt;% group_by(CITY, ANN) %&gt;% summarize() %&gt;% na.omit()\n\n# Creating plots\navg_sun$tooltip &lt;- c(paste0(avg_sun$CITY,\": \", avg_sun$ANN, \"%\"))\n\nsun1 &lt;- avg_sun[1:38,] %&gt;% \n  ggplot()+\n  geom_col_interactive(aes(x=reorder(CITY, ANN), y=ANN/100,\n                           tooltip = tooltip,\n                      data_id = ANN), fill=\"#0454a4\")+\n  coord_flip()+\n    labs(x=\"\", y=\"Average annual sunshine\")+\n  theme_minimal()+\n  theme(axis.text.x = element_text(vjust = 2))+\n  lims(y=c(0,1))+\n  scale_y_continuous(labels = scales::percent)+\n  scale_x_discrete(labels=NULL)\n\n\nsun2&lt;-avg_sun[39:76,] %&gt;% \n  ggplot()+\n  geom_col_interactive(aes(x=reorder(CITY, ANN), y=ANN/100,\n                           tooltip = tooltip,\n                      data_id = ANN), fill=\"#0454a4\")+\n  coord_flip()+\n    labs(x=\"\", y=\"Average annual sunshine\")+\n  theme_minimal()+\n  theme(axis.text.x = element_text(vjust = 2))+\n  lims(y=c(0,1))+\n  scale_y_continuous(labels = scales::percent)+\n  scale_x_discrete(labels=NULL)\n\nsun3&lt;-avg_sun[77:115,] %&gt;% \n  ggplot()+\n  geom_col_interactive(aes(x=reorder(CITY, ANN), y=ANN/100,\n                           tooltip = tooltip,\n                      data_id = ANN), fill=\"#0454a4\")+\n  coord_flip()+\n    labs(x=\"\", y=\"Average annual sunshine\")+\n  theme_minimal()+\n  theme(axis.text.x = element_text(vjust = 2))+\n  lims(y=c(0,1))+\n  scale_y_continuous(labels = scales::percent)+\n  scale_x_discrete(labels=NULL)\n\nsun4&lt;-avg_sun[116:153,] %&gt;% \n  ggplot()+\n  geom_col_interactive(aes(x=reorder(CITY, ANN), y=ANN/100,\n                           tooltip = tooltip,\n                      data_id = ANN), fill=\"#0454a4\")+\n  coord_flip()+\n    labs(x=\"\", y=\"Average annual sunshine\")+\n  theme_minimal()+\n  theme(axis.text.x = element_text(vjust = 2))+\n  lims(y=c(0,1))+\n  scale_y_continuous(labels = scales::percent)+\n  scale_x_discrete(labels=NULL)\n\n p&lt;-ggarrange(sun1, sun2, sun3, sun4, ncol=2, nrow=2, labels=c(\"A\",\"B\",\"C\",\"D\"))\ngirafe(\n  code = print(p + plot_annotation(title=\"How sunny is your hometown?\", subtitle = \"Measured by time of sun shine reaching earth from sunrise to sunset\", caption = \"A: Abilene TX - Des Moines, IA\\nB: Detroit, MI - Las Vegas, NV\\nC: Lihue, HI - Providence, RI\\nD: Pueblo, CO - Yap- W Caroline Is., PC\\nData from Kaggle.com: uploaded by user thedevastator\", theme = theme(plot.caption.position = \"plot\", plot.caption = element_text(hjust = 0)))),\n  height_svg = 9,\n  width_svg = NULL,\n  options = list(\n    opts_tooltip(css = tooltip_css, opacity = 1),\n    opts_sizing(width = .7),\n    opts_hover(css = \"fill:#0454a4;stroke-width:2;\"),\n    opts_hover_inv(css = \"opacity:0.1;\"),\n    opts_selection(\n      type = \"single\", \n      only_shiny = FALSE,\n      css = \"fill:#0454a4\"),\n    opts_zoom(max=4)\n  )\n)"
  },
  {
    "objectID": "posts/interactive-visualization-r-plotly-ggiraph.html#discussion",
    "href": "posts/interactive-visualization-r-plotly-ggiraph.html#discussion",
    "title": "Interactive Data Visualization in R with plotly and ggiraph",
    "section": "Discussion",
    "text": "Discussion\nThe interactive visualizations make it easy to explore both seasonal and geographic variation in sunshine. With plotly, users can highlight specific cities and compare seasonal changes. With ggiraph, tooltips and hover effects provide immediate context for annual averages across more than 150 cities.\nOne interesting finding is Los Angeles‚Äôs dip in May‚ÄìJune sunshine compared to adjacent months, a feature that might reflect local climate effects (e.g., ‚ÄúJune Gloom‚Äù)."
  },
  {
    "objectID": "posts/obesity-rates-shiny.html#workflow",
    "href": "posts/obesity-rates-shiny.html#workflow",
    "title": "Interactive Map in R with Shiny and Leaflet",
    "section": "Workflow",
    "text": "Workflow\n\nData source\n\nCDC public health dataset covering state-level nutrition, physical activity, and obesity indicators.\n\nShiny application\n\nBuilt with shiny for the app structure and reactivity.\n\nUser interface allows selection of different health indicators.\n\nLeaflet map\n\nUsed leaflet for the interactive choropleth map.\n\nStates are shaded according to health indicator values, with hover/click tooltips.\n\nDeployment\n\nHosted on shinyapps.io for public access."
  },
  {
    "objectID": "posts/obesity-rates-shiny.html#example-code-simplified",
    "href": "posts/obesity-rates-shiny.html#example-code-simplified",
    "title": "Interactive Map in R with Shiny and Leaflet",
    "section": "Example Code (simplified)",
    "text": "Example Code (simplified)\n\n&lt;p&gt;Shiny App&lt;/p&gt;"
  },
  {
    "objectID": "posts/obesity-rates-shiny.html#results",
    "href": "posts/obesity-rates-shiny.html#results",
    "title": "Interactive Map in R with Shiny and Leaflet",
    "section": "Results",
    "text": "Results\nThe finished application allows users to explore public health trends interactively. By selecting variables, users can compare how nutrition, exercise, and obesity differ across states.\nThis project highlights how R‚Äôs Shiny and Leaflet packages can be combined to produce data-driven tools for public health communication."
  },
  {
    "objectID": "posts/obesity-rates-shiny.html#application-preview",
    "href": "posts/obesity-rates-shiny.html#application-preview",
    "title": "Interactive Map in R with Shiny and Leaflet",
    "section": "Application Preview",
    "text": "Application Preview\n\n&lt;p&gt;Shiny App&lt;/p&gt;"
  },
  {
    "objectID": "posts/obesity-rates-shiny.html#discussion",
    "href": "posts/obesity-rates-shiny.html#discussion",
    "title": "Interactive Map in R with Shiny and Leaflet",
    "section": "Discussion",
    "text": "Discussion\nThe finished application allows users to explore public health trends interactively. By selecting variables, users can compare how nutrition, exercise, and obesity differ across states.\nThis project highlights how R‚Äôs Shiny and Leaflet packages can be combined to produce data-driven tools for public health communication."
  },
  {
    "objectID": "posts/obesity-rates-shiny.html#faq-building-interactive-maps-with-shiny-and-leaflet",
    "href": "posts/obesity-rates-shiny.html#faq-building-interactive-maps-with-shiny-and-leaflet",
    "title": "Interactive Map in R with Shiny and Leaflet",
    "section": "FAQ: Building Interactive Maps with Shiny and Leaflet",
    "text": "FAQ: Building Interactive Maps with Shiny and Leaflet\n\n\n\nHow do I add an interactive map to a Shiny app?\n\n\nUse leafletOutput() in the UI and renderLeaflet() in the server function.\n\n\n\n\nHow do I color states or regions by value?\n\n\nCreate a color palette with colorNumeric() or colorBin() and apply it to polygons.\n\n\n\n\nCan this app be deployed for free?\n\n\nYes. Shiny apps can be deployed to shinyapps.io with a free plan, though usage limits apply.\n\n\n\n\nWhat types of datasets work best with Leaflet?\n\n\nAny dataset with geographic boundaries or coordinates, such as shapefiles, GeoJSON, or state/county-level data."
  },
  {
    "objectID": "posts/rna-seq-data-wrangling.html#workflow",
    "href": "posts/rna-seq-data-wrangling.html#workflow",
    "title": "Biodegradation of PET Plastic: RNA-seq Analysis and Enzyme Discovery",
    "section": "Workflow",
    "text": "Workflow\n\nExperimental design\n\nBacteria were exposed to PET plastic, and RNA was sequenced to capture gene expression changes.\n\nPipeline development\n\nBuilt a custom RNA-seq pipeline for cleaning, alignment, and expression analysis.\n\nEnsured reproducibility and accuracy despite data loss in one control group.\n\nGene and enzyme analysis\n\nIdentified abnormal expression patterns linked to PET exposure.\n\nMapped expression results to protein and enzymatic functions.\n\nMetabolic pathway reconstruction\n\nProposed a hypothetical pathway for PET degradation.\n\nValidated results against enzyme databases and literature."
  },
  {
    "objectID": "posts/rna-seq-data-wrangling.html#results",
    "href": "posts/rna-seq-data-wrangling.html#results",
    "title": "Biodegradation of PET Plastic: RNA-seq Analysis and Enzyme Discovery",
    "section": "Results",
    "text": "Results\nThrough database searches, we found evidence of previously uncharacterized enzymes that may contribute to PET degradation. The metabolic pathways constructed from RNA-seq data showed promising targets for future biodegradation research.\n\n\n\nFig. 1 - RNA-seq pipeline and pathway reconstruction. Created with Biorender.\n\n\n\n\n\nFig. 2 - Proposed enzymatic pathway for PET degradation. A more complete pathway is described in the publication. Created with Biorender.\n\n\nThis work resulted in a publication and a conference presentation:\n- Presented at the Murdock College Science Research Conference\n- Published in the International Journal of Molecular Sciences:\nüëâ Microbial Consortia and Mixed Plastic Waste: Pangenomic Analysis Reveals Potential for Degradation of Multiple Plastic Types via Previously Identified PET Degrading Bacteria\nThe findings suggest opportunities for developing natural waste treatment systems using bacteria, as well as the possibility of engineering organisms to synthesize new plastic polymers from waste."
  },
  {
    "objectID": "posts/rna-seq-data-wrangling.html#acknowledgments",
    "href": "posts/rna-seq-data-wrangling.html#acknowledgments",
    "title": "Biodegradation of PET Plastic: RNA-seq Analysis and Enzyme Discovery",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nThis project was supported by the National Science Foundation (NSF), the Murdock Trust, and our collaborators at Reed College."
  },
  {
    "objectID": "posts/pet-plastic-biodegradation-rna-seq.html",
    "href": "posts/pet-plastic-biodegradation-rna-seq.html",
    "title": "Biodegradation of PET Plastic: RNA-seq Analysis and Enzyme Discovery",
    "section": "",
    "text": "This project was the focus of my undergraduate thesis at Willamette University, conducted with Dr.¬†Rosa Le√≥n-Zayas and Grace Sheehan. The goal was to identify enzymes involved in the biodegradation of polyethylene terephthalate (PET) plastic using bioinformatics and RNA-seq analysis.\nOliver F. Anderson, MS ‚Äì Computational Biologist, Data Scientist, and Research Consultant based in Portland, Oregon. I design data-driven solutions in bioinformatics, machine learning, and AI automation for research and biotech."
  },
  {
    "objectID": "posts/pet-plastic-biodegradation-rna-seq.html#workflow",
    "href": "posts/pet-plastic-biodegradation-rna-seq.html#workflow",
    "title": "Biodegradation of PET Plastic: RNA-seq Analysis and Enzyme Discovery",
    "section": "Workflow",
    "text": "Workflow\n\nExperimental design\n\nBacteria were exposed to PET plastic, and RNA was sequenced to capture gene expression changes.\n\nPipeline development\n\nBuilt a custom RNA-seq pipeline for cleaning, alignment, and expression analysis (Fig. 1).\n\nEnsured reproducibility and accuracy despite data loss in one control group.\n\nGene and enzyme analysis\n\nIdentified abnormal expression patterns linked to PET exposure.\n\nMapped expression results to protein and enzymatic functions.\n\nMetabolic pathway reconstruction\n\nProposed a hypothetical pathway for PET degradation (Fig. 2).\n\nValidated results against enzyme databases and literature."
  },
  {
    "objectID": "posts/pet-plastic-biodegradation-rna-seq.html#results",
    "href": "posts/pet-plastic-biodegradation-rna-seq.html#results",
    "title": "Biodegradation of PET Plastic: RNA-seq Analysis and Enzyme Discovery",
    "section": "Results",
    "text": "Results\nThrough database searches, we found evidence of previously uncharacterized enzymes that may contribute to PET degradation. The metabolic pathways constructed from RNA-seq data showed promising targets for future biodegradation research.\n\n\n\n\n\n\nFig. 1 - RNA-seq pipeline and pathway reconstruction. Created with Biorender.\n\n\n\n\nFigure¬†1\n\n\n\n\n\n\n\n\n\nFig. 2 - Proposed enzymatic pathway for PET degradation. A more complete pathway is described in the publication. Created with Biorender.\n\n\n\n\nFigure¬†2"
  },
  {
    "objectID": "posts/pet-plastic-biodegradation-rna-seq.html#acknowledgments",
    "href": "posts/pet-plastic-biodegradation-rna-seq.html#acknowledgments",
    "title": "Biodegradation of PET Plastic: RNA-seq Analysis and Enzyme Discovery",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nThis project was supported by the National Science Foundation (NSF), the Murdock Trust, and our collaborators at Reed College."
  },
  {
    "objectID": "posts/proteinweaver-biological-networks-visualization.html",
    "href": "posts/proteinweaver-biological-networks-visualization.html",
    "title": "ProteinWeaver: Visualizing Biological Networks in their Functional Context",
    "section": "",
    "text": "ProteinWeaver is a web tool for exploring how proteins connect to biological pathways and processes. By combining molecular interaction data with Gene Ontology annotations, it highlights a protein‚Äôs functional context inside complex biological networks.\nThe project was developed at Reed College under the guidance of Dr.¬†Anna Ritz, with collaboration from Altaf Barelvi. You can try ProteinWeaver on the official website or view the source code on GitHub.\nOliver F. Anderson, MS ‚Äì Computational Biologist, Data Scientist, and Research Consultant based in Portland, Oregon. I design data-driven solutions in bioinformatics, machine learning, and AI automation for research and biotech."
  },
  {
    "objectID": "posts/proteinweaver-biological-networks-visualization.html#workflow",
    "href": "posts/proteinweaver-biological-networks-visualization.html#workflow",
    "title": "ProteinWeaver: Visualizing Biological Networks in their Functional Context",
    "section": "Workflow",
    "text": "Workflow\n\nDatabase & interaction data\n\nImport protein‚Äìprotein, regulatory, and protein‚ÄìGO term associations from curated databases.\nStandardize identifiers for consistency across datasets.\nImport into Neo4j, a graph database.\nHosts data for seven model organisms: Arabiposis thaliana, Bacillus subtilis, Caenorhabditis elegans, Danio rerio, Drosophila melanogaster, Escherichia coli, & Saccharomyces cerevisiae.\n\nUser query setup\n\nInput a protein of interest along with a Gene Ontology (GO) term.\nChoose the type of network to be displayed (Physical, Regulatory, or Both).\nChoose between two different pathfinding algorithms (Nodes and Paths).\nAdjust k (number of nodes to include in the Nodes mode or number of shortest paths to include in the Paths mode).\n\nNetwork construction\n\nBuild a subnetwork centered around the query protein and its connections to the chosen GO term.\nAnnotate edges with interaction type (regulatory or physical).\n\nVisualization in the browser\n\nRender the subnetwork interactively using Cytoscape.js.\nDisplay node and edge attributes, including protein names, GO terms, and interaction evidence.\n\nWeb deployment\n\nHost the tool on a public server for interactive use.\nSource code is open and reproducible on GitHub."
  },
  {
    "objectID": "posts/pet-plastic-biodegradation-rna-seq.html#discussion",
    "href": "posts/pet-plastic-biodegradation-rna-seq.html#discussion",
    "title": "Biodegradation of PET Plastic: RNA-seq Analysis and Enzyme Discovery",
    "section": "Discussion",
    "text": "Discussion\nThis work resulted in a publication and a conference presentation:\n- Presented at the Murdock College Science Research Conference\n- Published in the International Journal of Molecular Sciences:\nüëâ Microbial Consortia and Mixed Plastic Waste: Pangenomic Analysis Reveals Potential for Degradation of Multiple Plastic Types via Previously Identified PET Degrading Bacteria\nThe findings suggest opportunities for developing natural waste treatment systems using bacteria, as well as the possibility of engineering organisms to synthesize new plastic polymers from waste."
  },
  {
    "objectID": "posts/proteinweaver-biological-networks-visualization.html#results",
    "href": "posts/proteinweaver-biological-networks-visualization.html#results",
    "title": "ProteinWeaver: Visualizing Biological Networks in their Functional Context",
    "section": "Results",
    "text": "Results\n\n\n\nFig. 1 ‚Äì Screenshot of an example ProteinWeaver query.\n\n\n\nQuery: Egfr + GO:0016055 (Wnt signaling pathway), D. melanogaster (7227), k=10, Nodes mode, and Mixed (both Physical and Regulatory) interactions.\nNetwork: 11 nodes, 58 edges.\nNodes are sized based on their degrees. High-degree nodes often include key regulators and adapter proteins.\nSolid, undirected edges mark protein‚Äìprotein links.\nDashed, directed edges show regulatory interactions.\nRed circles indicate the queried node.\nBlue squares indicate proteins annotated to the queried GO term.\nYellow circles indicate proteins on the path from the source node to the GO-annotated nodes."
  },
  {
    "objectID": "posts/proteinweaver-biological-networks-visualization.html#discussion",
    "href": "posts/proteinweaver-biological-networks-visualization.html#discussion",
    "title": "ProteinWeaver: Visualizing Biological Networks in their Functional Context",
    "section": "Discussion",
    "text": "Discussion\nProteinWeaver makes it possible to frame proteins in terms of specific biological functions. Instead of exploring large, undifferentiated networks, users can query with a single protein and a Gene Ontology term to see how that protein connects to a process of interest within a mixed interaction network.\nIn practice, this approach helps identify proteins that may be assocatied with processes that they are not yet known for. For example, Ret and Egfr are not yet annotated to the ‚ÄúWnt signaling pathway‚Äù GO term but could be targets for further investigation if they are connected to many proteins annotated to the GO term. This can help identify novel processes or functions for proteins.\nWhile the tool already supports interactive exploration in the browser, the exported JSON networks also integrate smoothly with external analysis pipelines. This flexibility means ProteinWeaver can be used for hypothesis generation, quick visualization, downstream statistical modeling, or as part of larger workflows in bioinformatics projects.\nThis work resulted in a publication and a poster presentation:\n- Presented at the RSGDREAM 2023 conference\n- Published in: üëâ PLOS ONE"
  },
  {
    "objectID": "posts/proteinweaver-biological-networks-visualization.html#faq-using-proteinweaver",
    "href": "posts/proteinweaver-biological-networks-visualization.html#faq-using-proteinweaver",
    "title": "ProteinWeaver: Visualizing Biological Networks in their Functional Context",
    "section": "FAQ: Using ProteinWeaver",
    "text": "FAQ: Using ProteinWeaver\n\n\n\nHow does ProteinWeaver connect proteins to Gene Ontology terms?\n\n\nProteinWeaver maps proteins to GO terms using curated annotations. It then traces connections between the queried protein and proteins annotated to the queried process by building subnetworks from interaction data.\n\n\n\n\nCan I export a network from ProteinWeaver?\n\n\nYes. Networks can be exported as JSON for use in Cytoscape.js or download the current network view as a PNG.\n\n\n\n\nWhich types of interactions are included in the network?\n\n\nNetworks may include protein‚Äìprotein, regulatory interactions, or both. Edges can be filtered and are styled by interaction type.\n\n\n\n\nIs ProteinWeaver limited to one organism?\n\n\nThe current deployment supports seven species (Arabiposis thaliana, Bacillus subtilis, Caenorhabditis elegans, Danio rerio, Drosophila melanogaster, Escherichia coli, & Saccharomyces cerevisiae), but each query is scoped to a single taxon at a time to avoid cross-species artifacts.\n\n\n\n\nDo I need to install anything to use ProteinWeaver?\n\n\nNo.¬†ProteinWeaver runs entirely in the browser."
  },
  {
    "objectID": "posts/olympic-track-field-body-composition.html",
    "href": "posts/olympic-track-field-body-composition.html",
    "title": "Olympic Track & Field Body Composition: Event-Level Patterns",
    "section": "",
    "text": "Track and field athletes bring different body types to their events, and those differences often reflect the physical demands of each discipline. In this project, I analyzed medalists from Olympic track and field using the TidyTuesday dataset (July 27, 2021). The goal was to explore how height and weight vary across events and to see whether distinct patterns emerge between sprinters, distance runners, jumpers, and throwers.\nOliver F. Anderson, MS ‚Äì Computational Biologist, Data Scientist, and Research Consultant based in Portland, Oregon. I design data-driven solutions in bioinformatics, machine learning, and AI automation for research and biotech."
  },
  {
    "objectID": "posts/olympic-track-field-body-composition.html#code-results",
    "href": "posts/olympic-track-field-body-composition.html#code-results",
    "title": "Olympic Track & Field Body Composition: Event-Level Patterns",
    "section": "Code & Results",
    "text": "Code & Results\n\n\nLook at the code\n# load packages and read in data from tidyTuesday\nlibrary(tidyverse)\nlibrary(colorspace)\nlibrary(patchwork)\nlibrary(DT)\nolympics &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-07-27/olympics.csv')\n# head(olympics)\n\n# I am interested in looking at track and field (athletics) medalists\nathletics &lt;- olympics %&gt;% \n  filter(sport==\"Athletics\",\n         !is.na(medal))\n\nathletics$sex &lt;- as.factor(athletics$sex)\n\nathletics_colnames &lt;- c(\"ID\", \"Name\", \"Sex\", \"Age\", \"Height\",\n                        \"Weight\", \"Team\", \"NOC\", \"Games\", \"Year\",\n                        \"Season\", \"City\", \"Sport\", \"Event\",\n                        \"Medal\")\n\nDT::datatable(athletics, colnames = athletics_colnames, caption = htmltools::tags$caption(style = \"caption-side: bottom; text-align: center;\", htmltools::strong(\"Table 1: Olympic Track & Field Medalists\")), filter = \"top\", options = list(pageLength = 5, autoWidth = TRUE))\n\n\n\n\n\n\nAfter filtering the data to focus on track and field medalists, I separated the athletes by sex and visualized their height and weight across different events.\n\n\nLook at the code\n# initial exploration\nathletics %&gt;% \n  filter(sex==\"F\") %&gt;% \n  ggplot(aes(height, weight, color=event))+\n  geom_point()\n\n\n\n\n\n\n\n\n\nTo simplify the analysis, I selected a few events and grouped them into categories such as Distance, Mid-Distance, Sprints, Jumps, and Throws. I then refined the visualizations, resulting in a cleaner and more understandable plot.\n\n\nLook at the code\n# there are so many events so lets choose a few events that represent some categories\n# distance: 10k, 5k\n# mid-distance: 800m, 1500m\n# sprints: 100m, 400m\n# jumps: long jump, triple jump\n# throws: shot put, discus, javelin\nathletics$event &lt;- gsub(\"Athletics Women's \", \"\", athletics$event)\nathletics$event &lt;- gsub(\"Athletics Men's \", \"\", athletics$event)\n\nathletics &lt;- athletics %&gt;% \n  filter(event == c(\"10,000 metres\", \"5,000 metres\", \"800 metres\",\"1,500 metres\", \"100 metres\", \"400 metres\", \"Long Jump\", \"Triple Jump\", \"Shot Put\", \"Discus Throw\", \"Javelin Throw\"))\n\nathletics %&gt;% \n  ggplot(aes(height, weight, color=event))+\n  geom_point(alpha=0.5)\n\n\n\n\n\n\n\n\n\nLook at the code\n# this is still too much, let's group them\nathletics &lt;- athletics %&gt;% \n  mutate(event_type = case_when( \n  event %in% c(\"10,000 metres\", \"5,000 metres\") ~ \"Distance\",\n  event %in% c(\"800 metres\",\"1,500 metres\") ~ \"Mid-distance\",\n  event %in% c(\"100 metres\", \"400 metres\") ~ \"Sprints\",\n  event %in% c(\"Long Jump\", \"Triple Jump\", \"High Jump\") ~ \"Jumps\",\n  event %in% c(\"Shot Put\", \"Discus Throw\", \"Javelin Throw\") ~ \"Throws\",\n))\n\n# now it's time to subset by sex\nathletics_f &lt;- athletics %&gt;% \n  filter(sex==\"F\")\n\nathletics_m &lt;- athletics %&gt;% \n  filter(sex==\"M\")\n\n# plot female\nathletics_f %&gt;% \n  ggplot(aes(height, weight, color=event_type))+\n  geom_point(alpha=0.5)\n\n\n\n\n\n\n\n\n\nThis is a much easier graphic to understand so I decided to beautify it.\n\n\nLook at the code\n# putting it together\n(( p1 &lt;- athletics_f %&gt;% \n  ggplot(aes(height, weight, color=event_type))+\n  geom_point(alpha=0.75)+\n  theme_minimal()+\n  scale_color_discrete_qualitative(\"Dark 3\")+\n  labs(title=\"Body Composition of Female \\nOlympic Medalists by Event\\n\", x=\"Height (cm)\", y=\"Weight (kg)\", color=\"Type of Track & Field Event\") ))\n\n\n\n\n\n\n\n\n\nThe findings reveal interesting trends. Female throwers generally exhibit larger body compositions, both in terms of weight and height, while distance runners tend to be smaller and lighter compared to other athletes. Jumpers, on the other hand, show either tall stature (likely due to high jumpers) or body compositions similar to sprinters. Short sprinters demonstrate a balanced distribution without skew in either height or weight, while mid-distance runners appear slightly lighter and shorter than their short sprinter counterparts. The sprinters, as a group, exhibit similar body types, with an average height of around 170 cm and weight of 60 kg.\n\n\nLook at the code\n# putting it together\n(( p2 &lt;- athletics_m %&gt;% \n  ggplot(aes(height, weight, color=event_type))+\n  geom_point(alpha=0.75)+\n  theme_minimal()+\n  scale_color_discrete_qualitative(\"Dark 3\")+\n  labs(title=\"Body Composition of Male \\nOlympic Medalists by Event\\n\", x=\"Height (cm)\", y=\"Weight (kg)\", color=\"Type of Track & Field Event\") ))\n\n\n\n\n\n\n\n\n\nSimilar patterns emerge among male Olympic medalists. Throwers dominate the upper right quadrant, indicating their tendency to be taller and heavier than other athletes. Like their female counterparts, male distance runners tend to have lighter and shorter body compositions. Jumpers and sprinters showcase comparable body types, with mid-distance runners falling between short sprinters and distance runners."
  },
  {
    "objectID": "posts/olympic-track-field-body-composition.html#workflow",
    "href": "posts/olympic-track-field-body-composition.html#workflow",
    "title": "Olympic Track & Field Body Composition: Event-Level Patterns",
    "section": "Workflow",
    "text": "Workflow\n\nLoad and prepare the dataset\n\nPulled Olympic athlete data from the TidyTuesday repository\nFiltered for track and field (athletics) medalists.\nConverted sex to a factor and standardized column labels for clarity.\n\nInitial exploration\n\nPlotted raw height and weight values by event to get a sense of variation.\nNoticed dense overlaps across events, suggesting the need for grouping.\n\nGroup events into categories\n\nDistance: 5,000 m, 10,000 m\nMid-distance: 800 m, 1,500 m\nSprints: 100 m, 400 m\nJumps: long jump, triple jump, high jump\nThrows: shot put, discus, javelin\n\nSubset by sex\n\nCreated separate data frames for female (athletics_f) and male (athletics_m) athletes.\nAllowed for side-by-side comparison of body composition trends.\n\nRefine visualizations\n\nBuilt scatterplots of height vs.¬†weight, colored by event category.\nApplied transparency (alpha) to handle overlapping points.\nImproved readability with theme_minimal() and color palettes from colorspace.\n\nFinal output\n\nProduced two plots: one for female medalists, one for male medalists."
  },
  {
    "objectID": "posts/olympic-track-field-body-composition.html#discussion",
    "href": "posts/olympic-track-field-body-composition.html#discussion",
    "title": "Olympic Track & Field Body Composition: Event-Level Patterns",
    "section": "Discussion",
    "text": "Discussion\nInterestingly, I was surprised to discover that throwers tend to be significantly taller than other athletes, as I initially assumed jumpers would be the tallest, given the specific demands of high jump. The realization that distance runners tend to be shorter, which hadn‚Äôt caught my attention previously, could be due to height-to-weight ratio. Being lighter appears advantageous for distance runners, and a shorter stature could contribute to achieving this goal.\nThese data align with my anectodal observations of track and field events. The trends indicate that specific events attract athletes with distinct body sizes, likely due to inherent advantages associated with their builds. This project has been a fun way to combine my passion for track and field with data science techniques. Please reach out if you have any project ideas or would like to collaborate."
  },
  {
    "objectID": "posts/olympic-track-field-body-composition.html#faq-olympic-body-composition-analysis",
    "href": "posts/olympic-track-field-body-composition.html#faq-olympic-body-composition-analysis",
    "title": "Olympic Track & Field Body Composition: Event-Level Patterns",
    "section": "FAQ: Olympic Body Composition Analysis",
    "text": "FAQ: Olympic Body Composition Analysis\n\n\n\nWhere does the dataset come from?\n\n\nThe data was published as part of the TidyTuesday project (July 27, 2021) and includes Olympic athletes across many sports and years.\n\n\n\n\nHow were the events grouped into categories?\n\n\nEvents were grouped into five categories: Distance (5,000 m, 10,000 m), Mid-distance (800 m, 1,500 m), Sprints (100 m, 400 m), Jumps (long, triple, high jump), and Throws (shot put, discus, javelin).\n\n\n\n\nWhy focus only on medalists?\n\n\nFiltering to medalists provides a focused view of athletes who reached the highest level of performance, making body composition patterns clearer.\n\n\n\n\nWhat trends stand out between male and female athletes?\n\n\nIn both groups, throwers are taller and heavier, distance runners are shorter and lighter, and sprinters and jumpers cluster in between.\n\n\n\n\nCan this analysis predict performance?\n\n\nNo.¬†The visualizations highlight correlations but do not establish causation. Many factors beyond height and weight‚Äîtraining, technique, physiology‚Äîaffect athletic outcomes."
  },
  {
    "objectID": "posts/olympic-track-field-body-composition-r.html",
    "href": "posts/olympic-track-field-body-composition-r.html",
    "title": "Olympic Track & Field Body Composition: Event-Level Patterns",
    "section": "",
    "text": "Track and field athletes bring different body types to their events, and those differences often reflect the physical demands of each discipline. In this project, I analyzed medalists from Olympic track and field using the TidyTuesday dataset (July 27, 2021). The goal was to explore how height and weight vary across events and to see whether distinct patterns emerge between sprinters, distance runners, jumpers, and throwers.\nOliver F. Anderson, MS ‚Äì Computational Biologist, Data Scientist, and Research Consultant based in Portland, Oregon. I design data-driven solutions in bioinformatics, machine learning, and AI automation for research and biotech."
  },
  {
    "objectID": "posts/olympic-track-field-body-composition-r.html#workflow",
    "href": "posts/olympic-track-field-body-composition-r.html#workflow",
    "title": "Olympic Track & Field Body Composition: Event-Level Patterns",
    "section": "Workflow",
    "text": "Workflow\n\nLoad and prepare the dataset\n\nPulled Olympic athlete data from the TidyTuesday repository\nFiltered for track and field (athletics) medalists.\nConverted sex to a factor and standardized column labels for clarity.\n\nInitial exploration\n\nPlotted raw height and weight values by event to get a sense of variation.\nNoticed dense overlaps across events, suggesting the need for grouping.\n\nGroup events into categories\n\nDistance: 5,000 m, 10,000 m\nMid-distance: 800 m, 1,500 m\nSprints: 100 m, 400 m\nJumps: long jump, triple jump, high jump\nThrows: shot put, discus, javelin\n\nSubset by sex\n\nCreated separate data frames for female (athletics_f) and male (athletics_m) athletes.\nAllowed for side-by-side comparison of body composition trends.\n\nRefine visualizations\n\nBuilt scatterplots of height vs.¬†weight, colored by event category.\nApplied transparency (alpha) to handle overlapping points.\nImproved readability with theme_minimal() and color palettes from colorspace.\n\nFinal output\n\nProduced two plots: one for female medalists, one for male medalists."
  },
  {
    "objectID": "posts/olympic-track-field-body-composition-r.html#code-results",
    "href": "posts/olympic-track-field-body-composition-r.html#code-results",
    "title": "Olympic Track & Field Body Composition: Event-Level Patterns",
    "section": "Code & Results",
    "text": "Code & Results\n\n\nLook at the code\n# load packages and read in data from tidyTuesday\nlibrary(tidyverse)\nlibrary(colorspace)\nlibrary(patchwork)\nlibrary(DT)\nolympics &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-07-27/olympics.csv')\n# head(olympics)\n\n# I am interested in looking at track and field (athletics) medalists\nathletics &lt;- olympics %&gt;% \n  filter(sport==\"Athletics\",\n         !is.na(medal))\n\nathletics$sex &lt;- as.factor(athletics$sex)\n\nathletics_colnames &lt;- c(\"ID\", \"Name\", \"Sex\", \"Age\", \"Height\",\n                        \"Weight\", \"Team\", \"NOC\", \"Games\", \"Year\",\n                        \"Season\", \"City\", \"Sport\", \"Event\",\n                        \"Medal\")\n\nDT::datatable(athletics, colnames = athletics_colnames, caption = htmltools::tags$caption(style = \"caption-side: bottom; text-align: center;\", htmltools::strong(\"Table 1: Olympic Track & Field Medalists\")), filter = \"top\", options = list(pageLength = 5, autoWidth = TRUE))\n\n\n\n\n\n\nAfter filtering the data to focus on track and field medalists, I separated the athletes by sex and visualized their height and weight across different events.\n\n\nLook at the code\n# initial exploration\nathletics %&gt;% \n  filter(sex==\"F\") %&gt;% \n  ggplot(aes(height, weight, color=event))+\n  geom_point()\n\n\n\n\n\n\n\n\n\nTo simplify the analysis, I selected a few events and grouped them into categories such as Distance, Mid-Distance, Sprints, Jumps, and Throws. I then refined the visualizations, resulting in a cleaner and more understandable plot.\n\n\nLook at the code\n# there are so many events so lets choose a few events that represent some categories\n# distance: 10k, 5k\n# mid-distance: 800m, 1500m\n# sprints: 100m, 400m\n# jumps: long jump, triple jump\n# throws: shot put, discus, javelin\nathletics$event &lt;- gsub(\"Athletics Women's \", \"\", athletics$event)\nathletics$event &lt;- gsub(\"Athletics Men's \", \"\", athletics$event)\n\nathletics &lt;- athletics %&gt;% \n  filter(event == c(\"10,000 metres\", \"5,000 metres\", \"800 metres\",\"1,500 metres\", \"100 metres\", \"400 metres\", \"Long Jump\", \"Triple Jump\", \"Shot Put\", \"Discus Throw\", \"Javelin Throw\"))\n\nathletics %&gt;% \n  ggplot(aes(height, weight, color=event))+\n  geom_point(alpha=0.5)\n\n\n\n\n\n\n\n\n\nLook at the code\n# this is still too much, let's group them\nathletics &lt;- athletics %&gt;% \n  mutate(event_type = case_when( \n  event %in% c(\"10,000 metres\", \"5,000 metres\") ~ \"Distance\",\n  event %in% c(\"800 metres\",\"1,500 metres\") ~ \"Mid-distance\",\n  event %in% c(\"100 metres\", \"400 metres\") ~ \"Sprints\",\n  event %in% c(\"Long Jump\", \"Triple Jump\", \"High Jump\") ~ \"Jumps\",\n  event %in% c(\"Shot Put\", \"Discus Throw\", \"Javelin Throw\") ~ \"Throws\",\n))\n\n# now it's time to subset by sex\nathletics_f &lt;- athletics %&gt;% \n  filter(sex==\"F\")\n\nathletics_m &lt;- athletics %&gt;% \n  filter(sex==\"M\")\n\n# plot female\nathletics_f %&gt;% \n  ggplot(aes(height, weight, color=event_type))+\n  geom_point(alpha=0.5)\n\n\n\n\n\n\n\n\n\nThis is a much easier graphic to understand so I decided to beautify it.\n\n\nLook at the code\n# putting it together\n(( p1 &lt;- athletics_f %&gt;% \n  ggplot(aes(height, weight, color=event_type))+\n  geom_point(alpha=0.75)+\n  theme_minimal()+\n  scale_color_discrete_qualitative(\"Dark 3\")+\n  labs(title=\"Body Composition of Female \\nOlympic Medalists by Event\\n\", x=\"Height (cm)\", y=\"Weight (kg)\", color=\"Type of Track & Field Event\") ))\n\n\n\n\n\n\n\n\n\nThe findings reveal interesting trends. Female throwers generally exhibit larger body compositions, both in terms of weight and height, while distance runners tend to be smaller and lighter compared to other athletes. Jumpers, on the other hand, show either tall stature (likely due to high jumpers) or body compositions similar to sprinters. Short sprinters demonstrate a balanced distribution without skew in either height or weight, while mid-distance runners appear slightly lighter and shorter than their short sprinter counterparts. The sprinters, as a group, exhibit similar body types, with an average height of around 170 cm and weight of 60 kg.\n\n\nLook at the code\n# putting it together\n(( p2 &lt;- athletics_m %&gt;% \n  ggplot(aes(height, weight, color=event_type))+\n  geom_point(alpha=0.75)+\n  theme_minimal()+\n  scale_color_discrete_qualitative(\"Dark 3\")+\n  labs(title=\"Body Composition of Male \\nOlympic Medalists by Event\\n\", x=\"Height (cm)\", y=\"Weight (kg)\", color=\"Type of Track & Field Event\") ))\n\n\n\n\n\n\n\n\n\nSimilar patterns emerge among male Olympic medalists. Throwers dominate the upper right quadrant, indicating their tendency to be taller and heavier than other athletes. Like their female counterparts, male distance runners tend to have lighter and shorter body compositions. Jumpers and sprinters showcase comparable body types, with mid-distance runners falling between short sprinters and distance runners."
  },
  {
    "objectID": "posts/olympic-track-field-body-composition-r.html#discussion",
    "href": "posts/olympic-track-field-body-composition-r.html#discussion",
    "title": "Olympic Track & Field Body Composition: Event-Level Patterns",
    "section": "Discussion",
    "text": "Discussion\nInterestingly, I was surprised to discover that throwers tend to be significantly taller than other athletes, as I initially assumed jumpers would be the tallest, given the specific demands of high jump. The realization that distance runners tend to be shorter, which hadn‚Äôt caught my attention previously, could be due to height-to-weight ratio. Being lighter appears advantageous for distance runners, and a shorter stature could contribute to achieving this goal.\nThese data align with my anectodal observations of track and field events. The trends indicate that specific events attract athletes with distinct body sizes, likely due to inherent advantages associated with their builds. This project has been a fun way to combine my passion for track and field with data science techniques. Please reach out if you have any project ideas or would like to collaborate."
  },
  {
    "objectID": "posts/olympic-track-field-body-composition-r.html#faq-olympic-body-composition-analysis",
    "href": "posts/olympic-track-field-body-composition-r.html#faq-olympic-body-composition-analysis",
    "title": "Olympic Track & Field Body Composition: Event-Level Patterns",
    "section": "FAQ: Olympic Body Composition Analysis",
    "text": "FAQ: Olympic Body Composition Analysis\n\n\n\nWhere does the dataset come from?\n\n\nThe data was published as part of the TidyTuesday project (July 27, 2021) and includes Olympic athletes across many sports and years.\n\n\n\n\nHow were the events grouped into categories?\n\n\nEvents were grouped into five categories: Distance (5,000 m, 10,000 m), Mid-distance (800 m, 1,500 m), Sprints (100 m, 400 m), Jumps (long, triple, high jump), and Throws (shot put, discus, javelin).\n\n\n\n\nWhy focus only on medalists?\n\n\nFiltering to medalists provides a focused view of athletes who reached the highest level of performance, making body composition patterns clearer.\n\n\n\n\nWhat trends stand out between male and female athletes?\n\n\nIn both groups, throwers are taller and heavier, distance runners are shorter and lighter, and sprinters and jumpers cluster in between.\n\n\n\n\nCan this analysis predict performance?\n\n\nNo.¬†The visualizations highlight correlations but do not establish causation. Many factors beyond height and weight, such as training, technique, and physiology affect athletic outcomes."
  },
  {
    "objectID": "posts/grphin-graphlet-characterization.html",
    "href": "posts/grphin-graphlet-characterization.html",
    "title": "GRPhIN: Graphlet Characterization of Regulatory and Physical Interaction Networks",
    "section": "",
    "text": "GRPhIN (Graphlet Characterization of Regulatory and Physical Interaction Networks) is an algorithm designed to count small subnetworks, known as graphlets, and the specific node positions within them, called orbits. Unlike isolated protein‚Äìprotein interaction (PPI) networks or gene regulatory networks (GRNs), GRPhIN captures how regulatory and physical interactions coexist and form distinct structural patterns. This provides a richer functional context for understanding the roles of proteins in complex systems.\nYou can access the code on GitHub or read the paper in Bioinformatics Advances here. GRPhIN was selected as a full-length talk at GLBIO 2025.\nOliver F. Anderson, MS ‚Äì Computational Biologist, Data Scientist, and Research Consultant based in Portland, Oregon. I design data-driven solutions in bioinformatics, machine learning, and AI automation for research and biotech."
  },
  {
    "objectID": "posts/grphin-graphlet-characterization.html#workflow",
    "href": "posts/grphin-graphlet-characterization.html#workflow",
    "title": "GRPhIN: Graphlet Characterization of Regulatory and Physical Interaction Networks",
    "section": "Workflow",
    "text": "Workflow\n\nInput networks\n\nUndirected protein‚Äìprotein interaction (PPI) network.\nDirected regulatory network.\n\nGraphlet enumeration\n\nIdentify all 2- and 3-node mixed graphlets (regulatory, physical, and both edges).\nAssign unique identifiers to each graphlet type.\n\nOrbit labeling\n\nLabel node positions (orbits) within each graphlet.\nCapture the distinct roles proteins may play depending on interaction directionality.\n\nSorting & uniqueness\n\nApply orbit sorting to ensure consistent labeling.\nGenerate canonical representations of graphlets across isomorphic structures.\n\nOutput\n\nCounts of all graphlets and their associated orbits in the mixed network.\nData exportable for downstream statistical or comparative analysis.\n\n\n\n\n\nFig. 1 - Orbit labeling and graphlet sorting. A) Unique edges and orbit in an RPI graph (orbit 0 indicates a non-edge; orbits 1‚Äì7 are mapped to the five distinct edge types). B) Sorting node orbits in ascending order maintains a unique graphlet structure. C) Sorting isomorphisms result in the same unique set of integer pairs."
  },
  {
    "objectID": "posts/grphin-graphlet-characterization.html#results-discussion",
    "href": "posts/grphin-graphlet-characterization.html#results-discussion",
    "title": "GRPhIN: Graphlet Characterization of Regulatory and Physical Interaction Networks",
    "section": "Results & Discussion",
    "text": "Results & Discussion\nBy integrating regulatory and physical interactions, GRPhIN reveals structural patterns that are invisible when networks are analyzed separately. The algorithm highlights how proteins can act in multiple contexts. For example, proteins may serve as both transcriptional regulators and participants in physical complexes.\nGRPhIN provides: - Functional insight into proteins beyond a single network type. - The ability to compare structural motifs across organisms or experimental conditions. - A foundation for testing hypotheses about protein function in mixed interaction settings.\nThe method is already being used to benchmark motif counts across organisms and has applications in studying pathway regulation, protein complexes, and evolutionary comparisons.\n\n\n\nGraphlet and orbit labeling illustration\n\n\n\nFig. 1 - Orbit labeling and graphlet sorting. A) Unique edges and orbit in an RPI graph (orbit 0 indicates a non-edge; orbits 1‚Äì7 are mapped to the five distinct edge types). B) Sorting node orbits in ascending order maintains a unique graphlet structure. C) Sorting isomorphisms result in the same unique set of integer pairs."
  },
  {
    "objectID": "posts/grphin-graphlet-characterization.html#faq-using-grphin",
    "href": "posts/grphin-graphlet-characterization.html#faq-using-grphin",
    "title": "GRPhIN: Graphlet Characterization of Regulatory and Physical Interaction Networks",
    "section": "FAQ: Using GRPhIN",
    "text": "FAQ: Using GRPhIN\n\n\n\nWhat is a graphlet?\n\n\nGraphlets are small, connected subnetworks (2‚Äì5 nodes) that represent recurring topological patterns. GRPhIN currently focuses on 2- and 3-node graphlets in mixed interaction networks.\n\n\n\n\nWhy combine regulatory and physical interactions?\n\n\nAnalyzing PPI or regulatory networks alone misses the ways proteins act across interaction types. GRPhIN integrates both to capture the full range of structural roles proteins play.\n\n\n\n\nWhat are orbits?\n\n\nOrbits define the unique positions a node can occupy within a graphlet. By tracking orbits, GRPhIN characterizes the specific roles of proteins across different graphlet structures.\n\n\n\n\nWhere can I access GRPhIN?\n\n\nGRPhIN is open source on GitHub. A detailed description is available in the publication.\n\n\n\nI am grateful for the opportunity to have worked with Altaf Barelvi and Dr.¬†Anna Ritz on this project and get hands-on experience developing algorithms."
  },
  {
    "objectID": "posts/grphin-graphlet-characterization.html#discussion",
    "href": "posts/grphin-graphlet-characterization.html#discussion",
    "title": "GRPhIN: Graphlet Characterization of Regulatory and Physical Interaction Networks",
    "section": "Discussion",
    "text": "Discussion\nBy integrating regulatory and physical interactions, GRPhIN reveals structural patterns that are invisible when networks are analyzed separately. The algorithm highlights how proteins can act in multiple contexts. For example, proteins may serve as both transcriptional regulators and participants in physical complexes.\nGRPhIN provides: - Functional insight into proteins beyond a single network type. - The ability to compare structural motifs across organisms or experimental conditions. - A foundation for testing hypotheses about protein function in mixed interaction settings.\nThe method is already being used to benchmark motif counts across organisms and has applications in studying pathway regulation, protein complexes, and evolutionary comparisons.\nThis work resulted in a publication and a full-length talk:\n- Presented at the GLBIO 2025 conference\n- Published in: üëâBioinformatics Advances"
  },
  {
    "objectID": "posts/remote-currency-database-docker-api-scraping.html",
    "href": "posts/remote-currency-database-docker-api-scraping.html",
    "title": "Building a Remote Currency Database with Docker and API Scraping",
    "section": "",
    "text": "This project focused on building a currency exchange database that updates daily and can be accessed remotely.\nOliver F. Anderson, MS ‚Äì Computational Biologist, Data Scientist, and Research Consultant based in Portland, Oregon. I design data-driven solutions in bioinformatics, machine learning, and AI automation for research and biotech."
  },
  {
    "objectID": "posts/remote-currency-database-docker-api-scraping.html#workflow",
    "href": "posts/remote-currency-database-docker-api-scraping.html#workflow",
    "title": "Building a Remote Currency Database with Docker and API Scraping",
    "section": "Workflow",
    "text": "Workflow\nThe workflow combined API scraping, SQL database design, and deployment in a Docker container.\n\nExchange Rates: Scraped daily USD-based exchange rates from exchangerate.host.\nDatabase Deployment: Ran the SQL database inside a Docker container and hosted it on Railway.app for remote access.\nHistorical Data: Imported past exchange rate data to align with GDP growth periods.\nSQL Views: Created dynamic Views to automatically update monthly average exchange rates.\n\n\nAdditional Data Sources:\n\nWorldometers GDP growth data.\niban.com country names and currency codes."
  },
  {
    "objectID": "posts/remote-currency-database-docker-api-scraping.html#results",
    "href": "posts/remote-currency-database-docker-api-scraping.html#results",
    "title": "Building a Remote Currency Database with Docker and API Scraping",
    "section": "Results",
    "text": "Results\n\n\n\nFig 1. - Entity relationship diagram for the currency database. Primary keys and linking relationships are shown.\n\n\nThe database design linked exchange rates, GDP data, and currency codes into a single relational structure. Views simplified queries by producing rolling monthly averages.\nUsing R, I analyzed GDP growth alongside exchange rate shifts. The focus example was the fastest growing economies of 2017.\n\n\n\nFig 2. - Exchange rates compared to USD for the fastest growing economies of 2017. The US dollar performed strongly relative to other currencies."
  },
  {
    "objectID": "posts/remote-currency-database-docker-api-scraping.html#discussion",
    "href": "posts/remote-currency-database-docker-api-scraping.html#discussion",
    "title": "Building a Remote Currency Database with Docker and API Scraping",
    "section": "Discussion",
    "text": "Discussion\nThe analysis showed that while some countries had high GDP growth in 2017, their currencies weakened against the US dollar. The Euro, which often tracks closely with USD, also lagged during this period.\nThis highlights a key point in international comparisons: GDP growth figures can look different once exchange rate effects are considered. A strong dollar can exaggerate the underperformance of other currencies, making raw growth metrics less comparable across borders."
  },
  {
    "objectID": "posts/remote-currency-database-docker-api-scraping.html#faq-docker-data-scraping-and-financial-apis",
    "href": "posts/remote-currency-database-docker-api-scraping.html#faq-docker-data-scraping-and-financial-apis",
    "title": "Building a Remote Currency Database with Docker and API Scraping",
    "section": "FAQ: Docker, Data Scraping, and Financial APIs",
    "text": "FAQ: Docker, Data Scraping, and Financial APIs\n\n\n\nWhy use Docker?\n\n\nDocker made the database portable and easy to deploy on Railway.\n\n\n\n\nWhy scrape data instead of downloading CSVs?\n\n\nDaily API scraping ensured the database stayed current and automatically provides the most updated data.\n\n\n\n\nHow often does the database update?\n\n\nExchange rates are pulled once per day, while SQL Views provide rolling monthly averages.\n\n\n\n\nCan this workflow be applied to other financial data?\n\n\nYes. The structure works for any API-driven dataset where regular updates and historical context are important."
  }
]